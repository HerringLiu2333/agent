1. Plan Summary
Detect integer-overflow-based undersized allocations where a computed size (involving a user-controlled length) is passed to an allocator without overflow-safe helpers, followed by writes using the intended larger size, as shown pre-patch in copy_gl_to_skb_pkt.

2. Detection Steps
1) Step 1: Identify allocation-size computations — look for call sites to allocators (e.g., alloc_skb) where the size argument is a nontrivial arithmetic expression combining a variable length with constants or other variables (addition/subtraction). This maps to the pre-patch alloc_skb(...) with gl->tot_len + headers - pktshift (from [FUNCTION_CONTENT]); reduce false positives by focusing on sums that include at least one non-constant operand.
2) Step 2: Flag absence of overflow-safe helpers — within those size expressions, detect lack of overflow-checked helpers (e.g., size_add) around the addition of dynamic lengths and header sizes. This matches the patch switching to size_add (from [PATCH_DIFF]); mitigate FPs by excluding sites that already use size_add or equivalent overflow-safe helpers around the sum.
3) Step 3: Model 32-bit vulnerability context — treat arithmetic in size expressions as potentially 32-bit if operands are of types commonly 32-bit sized (e.g., u32, size_t on 32-bit kernels) or if code is in kernel subsystems where 32-bit builds exist. This aligns with the 32-bit wrap condition (from [PATCH_DESCRIPTION], [ROOTCAUSE_ANALYSIS]); reduce FPs by prioritizing expressions whose operands include 32-bit integral types or unannotated size_t without explicit 64-bit promotion.
4) Step 4: Detect user-controlled or externally-derived length participation — taint variables like gl->tot_len that derive from processing external inputs (e.g., from process_responses(), as noted) and flow into the size expression. This maps to “gl->tot_len is controlled by the user” (from [PATCH_DESCRIPTION], [ROOTCAUSE_ANALYSIS]); mitigate FPs by requiring that at least one operand in the size expression is a function parameter, struct field read from a parameter, or data returned from another function without prior bounds checks.
5) Step 5: Correlate allocation size with subsequent write size — in the same function, find subsequent calls that write/copy data into the allocated object where the write length equals the intended larger sum (e.g., __skb_put with gl->tot_len + headers - pktshift, skb_copy_to_linear_data...). This reflects the undersized allocation then OOB write pattern (from [FUNCTION_CONTENT], [ROOTCAUSE_ANALYSIS]); reduce FPs by requiring that the write length expression dataflows from the same operands used in the allocation size.
6) Step 6: Ensure mismatch risk exists — flag when the allocation used unchecked arithmetic, while subsequent writes use the same arithmetic (potentially intended total), indicating the allocation could be smaller than the writes under overflow. This maps directly to the root cause of integer wrap leading to heap OOB (from [ROOTCAUSE_ANALYSIS]); mitigate FPs by suppressing when both allocation and writes use the same overflow-safe helpers or are guarded by explicit non-overflow checks.
7) Step 7: Recognize header-size additions — treat patterns where a dynamic payload length is added to one or more sizeof(...) header constants as higher risk. This mirrors the “gl->tot_len + sizeof(header1) + sizeof(header2)” pattern (from [FUNCTION_CONTENT], [PATCH_DIFF]); reduce FPs by requiring at least one sizeof(...) in the sum plus a dynamic length.
8) Step 8: Account for subtractive offsets — accept subtracting small offsets (e.g., - pktshift) within the size expression as part of the same risk pattern, since subtraction doesn’t prevent overflow in prior additions. This is present as “... - pktshift” (from [FUNCTION_CONTENT]); mitigate FPs by ensuring pktshift is non-constant or small and the main risk remains in preceding additions.
9) Step 9: Prefer cases where allocator failure is not checked to guard writes — flag stronger when subsequent writes occur unconditionally after a successful allocation check and there is no revalidation of lengths. This aligns with the flow “if (!skb) return; then __skb_put(...); skb_copy...” (from [FUNCTION_CONTENT]); reduce FPs by ignoring paths where the write size is recomputed using a bounded variable or validated against skb capacity.
10) Step 10: Scope to kernel networking/RDMA patterns — prioritize allocators and writers specific to skb (alloc_skb, __skb_put, skb_copy_to_linear_data, skb_copy_to_linear_data_offset). This focuses on the subsystem implicated (from [FUNCTION_CONTENT], [ROOTCAUSE_ANALYSIS]); mitigate FPs by restricting to these well-known primitives or analogous kernel alloc/write pairs configured as a list.
11) Step 11: Cross-check with comments or assumptions — where available, note comments indicating assumed size relations (e.g., “assumes sizeof cpl_pass_accept_req >= sizeof cpl_rx_pkt”), which can mask implicit risks. This is present in the function comment (from [FUNCTION_CONTENT]); mitigate FPs by not relying on comments for final decision, only as supporting evidence.
12) Step 12: Report when all three hold: unchecked additive size in allocation, tainted/dynamic length involvement, and subsequent write(s) using the intended larger total — suggest remediation to use overflow-aware helpers as in the patch. This maps to the fix via size_add (from [PATCH_DIFF]) and root cause (from [ROOTCAUSE_ANALYSIS]); mitigate FPs by requiring this triad before alerting.

3. Target Elements
- Function call sites to allocators: alloc_skb (and similar kernel allocators if configured).
- Arithmetic expressions passed as allocation sizes.
- Subsequent data-write or length-commit calls: __skb_put, skb_copy_to_linear_data, skb_copy_to_linear_data_offset.
- Variables/fields representing lengths flowing from function parameters or external processing (e.g., gl->tot_len).
- sizeof(...) operands participating in size calculations.
- Conditional checks guarding allocation and subsequent writes.

4. Dataflow / Taint Considerations
- Treat function parameters and their reachable struct fields (e.g., gl->tot_len) as potential taint sources when used in size expressions, especially if noted as user-controlled (from [PATCH_DESCRIPTION], [ROOTCAUSE_ANALYSIS]).
- Track dataflow from these sources into allocation size expressions and into subsequent write length arguments to establish correlation.
- Consider taint preserved through simple arithmetic (add/sub) and casts without bounds enforcement.
- Optionally downgrade taint if explicit bounds checks against maximums of the target type or overflow-safe helpers are applied before allocation.

5. Validation & Test Cases
- Positive: A function allocating skb with alloc_skb(gl->tot_len + sizeof(H1) + sizeof(H2) - pktshift) and then calling __skb_put and skb_copy_* with the same sum, with no size_add usage (mirrors [FUNCTION_CONTENT]).
- Negative: Same function but using alloc_skb(size_add(gl->tot_len, sizeof(H1) + sizeof(H2)) - pktshift, ...) as in the patch (from [PATCH_DIFF]).
- Negative: Allocation preceded by explicit non-overflow guarding logic that ensures the sum cannot wrap (e.g., validated against UINT_MAX-sizeof(headers)), followed by writes using the validated size.
- Test harness notes: Run on kernel codebases including drivers/infiniband/hw/cxgb4/device.c and verify the checker flags the pre-patch version and is quiet on the patched hunk.

6. Estimated Effort & Priority
High — combines API modeling (allocators/writers), arithmetic pattern recognition, and intra-procedural dataflow correlation; high security impact per [ROOTCAUSE_ANALYSIS].

7. Likely False-Positive Sources & Mitigations
- Benign additions where operands are 64-bit or provably bounded: mitigate by type- and bound-aware heuristics.
- Uses of custom overflow-safe helpers not named size_add: allow configuration to whitelist additional helpers.
- Code paths where write sizes are clamped post-allocation: require correlation that the same unchecked sum feeds both allocation and writes without intervening bounds enforcement.
- Architectures where size_t is 64-bit: lower severity or suppress unless 32-bit types are involved in the expression.

8. Limitations & Assumptions
- Architecture width (32-bit vs 64-bit) may not be inferable from a single TU; assume risk when 32-bit-typed operands participate as in [ROOTCAUSE_ANALYSIS].
- Exact user-controlled provenance (e.g., process_responses()) cannot always be determined; we approximate via parameter/struct-field taint as suggested by [PATCH_DESCRIPTION].
- The plan focuses on skb-related APIs seen in [FUNCTION_CONTENT]; broader allocator/writer pairs would need additional API modeling not provided here.
- We cannot statically confirm runtime sizes of structs used in sizeof; we assume they are constants contributing to potential overflow per [FUNCTION_CONTENT].