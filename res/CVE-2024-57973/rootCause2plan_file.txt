1. Plan Summary
Detect allocation-size calculations that use unchecked integer addition with externally influenced lengths (e.g., packet-derived), then perform writes based on the intended (non-wrapped) size, risking integer overflow and heap buffer overflow, as in the pre-patch cxgb4 copy_gl_to_skb_pkt path.

2. Detection Steps
1) Step 1: Locate allocation calls with arithmetic size expressions — look for calls like alloc_skb (and similar allocators) whose size argument is formed by adding a variable length and header constants, possibly followed by a subtraction (pattern like X + const + const - Y) — this mirrors the vulnerable alloc_skb(gl->tot_len + sizeof(...) + sizeof(...) - pktshift) in [PATCH_DIFF]/[FILE_CONTENT]; mitigate FPs by focusing on known buffer allocators and requiring subsequent buffer writes.
2) Step 2: Tie the size variable to packet-derived input — identify that the variable is obtained from a structure passed down the RX path (e.g., gl->tot_len from pkt_gl supplied into copy_gl_to_skb_pkt via recv_rx_pkt/c4iw_uld_rx_handler as seen in [FILE_CONTENT]) — this maps to the root cause that gl->tot_len is user-controlled in [PATCH_DESCRIPTION]/[ROOTCAUSE_ANALYSIS]; reduce FPs by requiring the variable to originate from RX handler parameters or fields (pkt_gl) along the call chain.
3) Step 3: Check for subsequent writes based on the intended total — find calls like __skb_put and skb_copy_to_linear_data(_offset) using expressions that include the same length variable (e.g., gl->tot_len + headers - pktshift, and gl->tot_len - pktshift) as shown in [FILE_CONTENT] — this demonstrates the overflow-to-overwrite pathway described in [ROOTCAUSE_ANALYSIS]; suppress if writes are clearly capped by safe APIs or explicit tailroom checks.
4) Step 4: Confirm absence of overflow-safe helpers — ensure the allocation arithmetic is not wrapped in size_add, check_add_overflow, or equivalent helpers (the fix uses size_add per [PATCH_DIFF]/[PATCH_DESCRIPTION]) — this maps directly to the missing protection; suppress findings when size_add (or equivalent) is used to combine the tainted length with headers.
5) Step 5: Prioritize potentially narrow integer arithmetic — prefer cases where the expression is computed in 32-bit or size_t contexts likely to be 32-bit (as the issue is 32-bit-specific per [PATCH_DESCRIPTION]/[ROOTCAUSE_ANALYSIS]) — this aligns with the wraparound risk; mitigate FPs by lowering severity when operands are clearly 64-bit wide.
6) Step 6: Identify subexpression structure that risks wrap-before-subtract — detect when a large addition of user length and header constants precedes a small subtraction (e.g., - pktshift), as in [FILE_CONTENT] — this matches the overflow window noted in [ROOTCAUSE_ANALYSIS]; use this to rank findings higher without excluding other patterns.
7) Step 7: Compare allocation size expression to write sizes — verify that the total bytes written (sum of __skb_put and subsequent copies) is equal to or greater than the allocation argument (using the same tainted length), reflecting the heap overflow impact in [ROOTCAUSE_ANALYSIS] — suppress if the code ensures the copy size cannot exceed the allocated size via robust checks.
8) Step 8: Ensure the write path is reachable post-allocation — require a path where alloc_skb succeeds (e.g., !skb early-return is handled in [FILE_CONTENT]) and the writes occur — this confirms exploitability; suppress if all paths with writes already guard against overflow or null allocations.
9) Step 9: Correlate call chain for taint provenance — from c4iw_uld_rx_handler receiving a pkt_gl, to recv_rx_pkt, to copy_gl_to_skb_pkt using gl->tot_len, as shown in [FILE_CONTENT] — this demonstrates realistic dataflow from user-controlled input to allocation and writes; reduce FPs by requiring such a call-chain context or similar driver RX pipelines.
10) Step 10: Exclude patched-safe patterns — where the allocation uses size_add(gl->tot_len, header_sizes) as in [PATCH_DIFF], do not flag — this ensures the checker aligns with the intended fix and reduces noise.

3. Target Elements
- Memory allocation call sites: alloc_skb, kmalloc-like allocators taking a size argument.
- Arithmetic expressions forming allocation sizes, especially sums of a variable length plus sizeof constants and minor subtractions.
- Subsequent buffer-capacity setters and data copy calls: __skb_put, skb_copy_to_linear_data, skb_copy_to_linear_data_offset.
- Structure field reads of packet/gather list descriptors (e.g., pkt_gl->tot_len) passed from RX handlers.
- Control-flow/guard conditions preceding allocations and writes (overflow checks, tailroom checks).
- Call graph edges from RX entry points (c4iw_uld_rx_handler) through helper functions (recv_rx_pkt) to allocation sites (copy_gl_to_skb_pkt), per [FILE_CONTENT].

4. Dataflow / Taint Considerations
- Treat fields from RX path descriptors (e.g., pkt_gl->tot_len) as taint sources, since [PATCH_DESCRIPTION]/[ROOTCAUSE_ANALYSIS] indicate user control.
- Track taint through parameter passing from c4iw_uld_rx_handler to recv_rx_pkt to copy_gl_to_skb_pkt as in [FILE_CONTENT].
- Propagate taint into arithmetic expressions used for allocation sizes and subsequent write sizes; correlate reuse of the same tainted value across allocation and write sites.
- Consider sanitizers: size_add/check_add_overflow or explicit bounds checks that cap the tainted value to a safe maximum before use.

5. Validation & Test Cases
- Positive: Pre-patch snippet from [FILE_CONTENT]: alloc_skb(gl->tot_len + sizeof(cpl_pass_accept_req) + sizeof(rss_header) - pktshift, ...) followed by __skb_put and skb_copy_to_linear_data using gl->tot_len-based sizes — expect a finding.
- Negative: Patched snippet from [PATCH_DIFF]: alloc_skb(size_add(gl->tot_len, sizeof(cpl_pass_accept_req) + sizeof(rss_header)) - pktshift, ...) — expect no finding.
- Test harness notes: Run on the file before and after applying the patch; verify one report at the allocation in copy_gl_to_skb_pkt pre-patch and no report post-patch.

6. Estimated Effort & Priority
High — requires inter-procedural taint tracking from RX paths, expression equivalence/containment comparison between allocation and writes, and recognition of overflow-safe idioms.

7. Likely False-Positive Sources & Mitigations
- 64-bit-only builds where size_t arithmetic won’t overflow: mitigate by prioritizing 32-bit-typed operands or noting unknown architecture in the message.
- Presence of manual bounds checks not recognized: look for guards constraining the tainted length against a maximum that implies no overflow and suppress accordingly.
- Allocations followed by capped writes (e.g., limiting to skb tailroom): suppress when the copy length is clearly bounded by the allocated capacity.
- Non-user-controlled lengths: require taint provenance from RX inputs (pkt_gl or similar) or from functions documented as processing external inputs in [FILE_CONTENT].

8. Limitations & Assumptions
- Architecture width (32-bit vs 64-bit) cannot be determined statically from the provided code; the checker assumes potential 32-bit compilation as per [PATCH_DESCRIPTION]/[ROOTCAUSE_ANALYSIS].
- The exact taint source “process_responses()” is referenced in [PATCH_DESCRIPTION] but not present in [FILE_CONTENT]; the plan assumes pkt_gl->tot_len is externally influenced per [ROOTCAUSE_ANALYSIS].
- The checker may not precisely prove arithmetic overflow; it heuristically flags risky patterns lacking size_add/check_add_overflow or equivalent guards.