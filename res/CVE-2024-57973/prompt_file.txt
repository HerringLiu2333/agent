1. CVE Identifier
CVE-2024-57973

2. Vulnerability Type
Integer overflow leading to heap-based buffer overflow

3. Root Cause Summary
The function copy_gl_to_skb_pkt computed the allocation size using unchecked integer addition on 32-bit systems: gl->tot_len + sizeof(struct cpl_pass_accept_req) + sizeof(struct rss_header) - pktshift. Because gl->tot_len is user-controlled, this addition could wrap on 32-bit, causing alloc_skb to allocate an undersized sk_buff. Subsequent __skb_put and skb_copy_to_linear_data[_offset] used the intended (non-saturated) total payload and headers to fill the skb, resulting in writing beyond the allocated buffer. The patch replaces the vulnerable addition with size_add(), which detects overflow and prevents undersized allocation.

4. Kernel Subsystem Analysis
1) Affected Subsystem:
RDMA Chelsio cxgb4 driver (drivers/infiniband/hw/cxgb4), packet processing path building sk_buffs for CPL_RX_PKT in device.c

2) Pre-Patch Flaw:
In copy_gl_to_skb_pkt, the allocation size was computed with a plain addition using a user-controlled length on 32-bit systems: “alloc_skb(gl->tot_len + sizeof(struct cpl_pass_accept_req) + sizeof(struct rss_header) - pktshift, GFP_ATOMIC);”, which could overflow and wrap to a smaller size.

3) Trigger Condition:
On 32-bit systems, a crafted gl->tot_len (coming from process_responses(), as per patch description) large enough that gl->tot_len + sizeof(struct cpl_pass_accept_req) + sizeof(struct rss_header) exceeds size_t, causing integer wraparound.

4) Impact Mechanism:
- alloc_skb allocates a buffer smaller than the true required size due to wraparound.
- __skb_put and subsequent skb_copy_to_linear_data and skb_copy_to_linear_data_offset copy H + (gl->tot_len - pktshift) bytes (where H is header sizes), potentially exceeding the actual allocated buffer and causing a heap buffer overflow in the skb’s linear data area, leading to memory corruption and possible kernel crash.

5. Patch Analysis
1) Fix Approach:
Overflow-safe size calculation using size_add() to detect and handle integer overflow before allocation.

2) Key Code Changes:
- In copy_gl_to_skb_pkt, changed:
  “alloc_skb(gl->tot_len + sizeof(struct cpl_pass_accept_req) + sizeof(struct rss_header) - pktshift, GFP_ATOMIC);”
  to:
  “alloc_skb(size_add(gl->tot_len, sizeof(struct cpl_pass_accept_req) + sizeof(struct rss_header)) - pktshift, GFP_ATOMIC);”
This ensures that if gl->tot_len + headers overflows, the result saturates (SIZE_MAX) and alloc_skb fails, preventing subsequent writes.

3) Locking/Concurrency Impact:
None. The change is purely arithmetic validation; no locking or ordering modifications were made.

6. Broader Kernel Security Implications
Unchecked arithmetic involving user-controlled lengths in allocation size computations is a common source of kernel memory corruption, especially on 32-bit architectures. Using helpers like size_add() prevents wraparound and forces allocation failure paths, reducing exploitation surfaces. This patch reinforces the need for overflow-safe size calculations in network/RDMA drivers where packet-derived lengths influence memory allocations and copies.