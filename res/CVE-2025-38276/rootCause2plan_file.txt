1. Plan Summary
Detect cases where code waits on a locked XArray entry, calls xas_pause before dropping the XArray lock, then reloads the entry using the same xa_state, causing the iterator to advance and skip the intended entry.

2. Detection Steps
1) Step 1: Objective — find functions that implement “wait until entry unlocks” semantics. Signals — a loop conditioned on an entry lock check (e.g., dax_is_locked(entry)) and use of prepare_to_wait_exclusive plus a waitqueue derived from an xa_state and entry (as in dax_entry_waitqueue), based on [FILE_CONTENT]. FP mitigation — restrict to functions that use waitqueues and a TASK_UNINTERRUPTIBLE prepare_to_wait_exclusive, not generic resched points.

2) Step 2: Objective — detect the problematic sequence around dropping the XArray lock. Signals — within such a wait loop, the sequence xas_pause(xas); xas_unlock_irq(xas); schedule(); finish_wait(...); xas_lock_irq(xas), as shown pre-patch in wait_entry_unlocked_exclusive in [FILE_CONTENT] and fixed in [PATCH_DIFF]. FP mitigation — require presence of schedule() to confirm a blocking wait, and finish_wait to confirm the wait lifecycle.

3) Step 3: Objective — confirm that the code subsequently reloads “the current entry” using the advanced xa_state. Signals — a call to xas_load(xas) after reacquiring the lock to fetch the entry, with no intervening xas_set(xas, saved_index) reset, matching [ROOTCAUSE_ANALYSIS] description of reloading the next entry. FP mitigation — exclude if the code resets index via xas_set to a saved index before calling xas_load.

4) Step 4: Objective — confirm the intent to continue processing the same index after the reload. Signals — returned value is the reloaded entry (function returns entry) or the entry is used immediately for per-index operations (e.g., dax_busy_page, xas_clear_mark, dax_disassociate_entry), as seen in callers in [FILE_CONTENT]. FP mitigation — require the function to return the entry or use it in an index-stable operation, indicating reliance on not skipping.

5) Step 5: Objective — exclude safe patterns using xas_reset. Signals — if xas_reset(xas) is used instead of xas_pause in the wait path, do not flag (per [PATCH_DESCRIPTION] and [PATCH_DIFF], xas_reset does not advance). FP mitigation — hard-exclude functions that use xas_reset in the wait sequence.

6) Step 6: Objective — exclude benign uses of xas_pause for cooperative scheduling inside xas_for_each loops. Signals — detect xas_pause within a loop using xas_for_each/xas_for_each_marked and followed by cond_resched(), not accompanied by xas_load reload of the current entry, consistent with [PATCH_DESCRIPTION] note that xas_for_each handles index advancement. FP mitigation — require both: (a) use inside an xas_for_each loop and (b) no immediate xas_load of “current entry”; then do not flag.

7) Step 7: Objective — strengthen detection with caller context indicating impact. Signals — find call sites where the wait function (from Step 1–3) is invoked inside XArray scans (xas_for_each) in routines that act per-entry (e.g., dax_layout_busy_page_range and __dax_clear_dirty_range), both identified in [FILE_CONTENT] and [ROOTCAUSE_ANALYSIS]. FP mitigation — only add context to report; do not require to flag, to avoid missing standalone flawed helpers.

8) Step 8: Objective — ensure the xa_state pointer identity is preserved. Signals — track the same xa_state argument through the wait function and the subsequent xas_load, ensuring no aliasing/reassignment occurred. FP mitigation — restrict to straightforward cases where the same xa_state variable is passed and used.

9) Step 9: Objective — flag the vulnerability. Signals — all of: wait-on-locked-entry loop; xas_pause before dropping the lock and sleeping; reload with xas_load without resetting the index; entry used/returned as the current entry. FP mitigation — require the presence of TASK_UNINTERRUPTIBLE wait and schedule() to avoid catching non-wait scenarios.

3. Target Elements
- Functions operating on struct xa_state that implement wait-on-entry loops.
- Call sites of xas_pause, xas_unlock_irq, xas_lock_irq, schedule, finish_wait, xas_load.
- Loops using xas_for_each/xas_for_each_marked over XArray entries.
- Waitqueue setup via prepare_to_wait_exclusive and dax_entry_waitqueue.
- Entry lock checks (e.g., dax_is_locked(entry)) and subsequent per-entry actions.

4. Dataflow / Taint Considerations
- Track the xa_state pointer through the wait loop and across function boundaries to confirm the same state is paused, unlocked, slept, re-locked, and reloaded.
- Track the “entry” variable’s role as the current entry corresponding to xa_state->xa_index, especially when the function returns the reloaded entry or uses it immediately.
- Treat xas_set(xas, saved_index) and xas_reset(xas) as index reset sanitizers that break the vulnerability flow.

5. Validation & Test Cases
- Positive: Pre-patch wait_entry_unlocked_exclusive in [FILE_CONTENT]: while(dax_is_locked(entry)) { prepare_to_wait_exclusive; xas_pause; xas_unlock_irq; schedule; finish_wait; xas_lock_irq; entry = xas_load(xas); } → should be flagged.
- Positive: A synthetic helper that waits on a locked XArray entry with the same sequence and returns the reloaded entry without xas_set/xas_reset → flagged.
- Negative: Patched wait_entry_unlocked_exclusive using xas_reset(xas) instead of xas_pause (as per [PATCH_DIFF]) → not flagged.
- Negative: xas_pause used within xas_for_each loop followed by cond_resched and no xas_load of current entry (e.g., in dax_layout_busy_page_range and dax_writeback_mapping_range resched paths in [FILE_CONTENT]) → not flagged.
- Test harness notes: Run on fs/dax.c pre- and post-patch; expect one alert pre-patch (wait_entry_unlocked_exclusive) and zero post-patch.

6. Estimated Effort & Priority
Medium: requires modeling sequences and context around XArray iterator usage, but scoped to recognizable kernel patterns.

7. Likely False-Positive Sources & Mitigations
- Use of xas_pause in custom helpers that also reset the index via xas_set: mitigate by checking for xas_set/xas_reset before xas_load.
- Non-blocking uses of xas_pause: mitigate by requiring schedule() and finish_wait in the sequence.
- Complex aliasing of xa_state: mitigate by focusing on obvious same-variable flows and not attempting deep alias resolution.

8. Limitations & Assumptions
- Assumes xas_pause advances iteration and xas_reset does not, per [PATCH_DESCRIPTION]; the checker does not infer library semantics beyond this.
- Does not prove runtime locking correctness; only flags the sequence likely to cause skipping.
- Limited to detectable patterns similar to wait_entry_unlocked_exclusive; other subtle iterator misuse may evade detection if it lacks the same signals.
- Specific DAX entry lock checks (dax_is_locked) are used as signals from [FILE_CONTENT]; analogous patterns outside fs/dax may not be covered.