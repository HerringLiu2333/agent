1. Plan Summary
Detect functions that use IRQ-enabling lock primitives (e.g., guard(raw_spinlock_irq)) while being invoked under an already IRQ-disabled context established by their callers (e.g., via raw_spin_lock_irqsave or irq_get_desc_lock), which can re-enable interrupts prematurely on unlock.

2. Detection Steps
1) Step 1: Objective — Identify call sites where interrupts are disabled before a callee is invoked. Signals — A path with a call to raw_spin_lock_irqsave (or irq_get_desc_lock) followed by a direct/indirect call to a function, with no intervening irq restore/unlock until after the call (based on PATCH_DESCRIPTION and ROOTCAUSE_ANALYSIS). FP mitigation — Require dominance and path feasibility: ensure the call is post-dominated by the corresponding unlock/irq restore and that no enabling primitive appears before the callee.

2) Step 2: Objective — Propagate an “IRQ-disabled” state through the call graph. Signals — Interprocedural propagation from a caller with active irq-disabled state into the callee at call entry, unless an enabling primitive is encountered on the path. FP mitigation — Restrict propagation to known disable sources (raw_spin_lock_irqsave and wrappers like irq_get_desc_lock per PATCH_DESCRIPTION/ROOTCAUSE_ANALYSIS) and stop at known restore/unlock points (e.g., irq_put_desc_unlock).

3) Step 3: Objective — Within candidate callees, locate IRQ-enabling lock guards. Signals — Use of guard(raw_spinlock_irq) (per PATCH_DIFF/ROOTCAUSE_ANALYSIS), which pairs raw_spin_lock_irq with raw_spin_unlock_irq and thus enables interrupts on scope exit. FP mitigation — Exclude uses of guard(raw_spinlock) (the fixed pattern), and exclude irqsave/irqrestore variants which restore the prior state rather than unconditionally enabling.

4) Step 4: Objective — Detect non-RAII irq lock/unlock pairs that unconditionally enable interrupts. Signals — Presence of raw_spin_lock_irq/spin_lock_irq followed by raw_spin_unlock_irq/spin_unlock_irq in the same function scope. FP mitigation — Exclude pairs using irqsave/irqrestore; ensure the pair encloses the call’s execution path (i.e., the unlock is reachable on all returns).

5) Step 5: Objective — Confirm the problematic nesting: callee’s IRQ-enabling unlock is executed before the caller’s irq restore. Signals — The callee returns to a context where the caller still holds the irqsave-disabling lock (e.g., irq_put_desc_unlock not yet executed), matching the chain in PATCH_DESCRIPTION. FP mitigation — Require that the caller’s matching irq restore/unlock is post-call and not conditionally bypassed.

6) Step 6: Objective — Highlight specific risky resources (locks) involved. Signals — Inner lock objects (e.g., &its_dev->event_map.vlpi_lock per PATCH_DIFF) taken with an irq-enabling guard in an IRQ-disabled context. FP mitigation — Prefer reports where the inner lock is not the same lock as the outer one (different object), indicating true nested locking as in ROOTCAUSE_ANALYSIS.

7) Step 7: Objective — Reduce noise by excluding functions that self-manage IRQ state safely. Signals — In the callee, presence of local_irq_save/local_irq_restore-like save/restore semantics or guard variants that preserve prior state (not evidenced here). FP mitigation — Only report when the callee’s primitive is known to enable on exit (e.g., guard(raw_spinlock_irq) or unlock_irq), not when it restores to saved flags.

8) Step 8: Objective — Prioritize reports in IRQ management subsystems where the pattern is expected to be harmful. Signals — File/path or symbol context consistent with IRQ chip drivers (e.g., drivers/irqchip/, functions like its_irq_set_vcpu_affinity from ROOTCAUSE_ANALYSIS). FP mitigation — Assign higher confidence to these contexts; lower priority outside, but still report if the semantic pattern is strong.

9) Step 9: Objective — Detect similar wrapper-induced issues. Signals — Calls to wrapper functions like irq_get_desc_lock/irq_put_desc_unlock around a callee that uses guard(raw_spinlock_irq) internally (as in PATCH_DESCRIPTION). FP mitigation — Require that the wrapper pair dominates the callee call and that no enable occurs between wrapper lock and callee entry.

10) Step 10: Objective — Report with actionable guidance. Signals — Include the outer disabling site, callee name, inner irq-enabling primitive, and the suggested fix pattern (use plain spinlock guard), per PATCH_DIFF/ROOTCAUSE_ANALYSIS. FP mitigation — Only emit when both outer disable and inner irq-enabling primitive are confidently identified.

3. Target Elements
- Functions potentially called under irq-disabled context.
- Call sites dominated by raw_spin_lock_irqsave or irq_get_desc_lock and post-dominated by irq_put_desc_unlock or unlock_irqrestore.
- RAII guard macro uses: guard(raw_spinlock_irq) vs guard(raw_spinlock).
- Lock/unlock pairs using *_irq vs *_irqsave/restore.
- Lock boundary regions in callers and callees.

4. Dataflow / Taint Considerations
- Track a boolean “irq-disabled” state:
  - Sources: raw_spin_lock_irqsave in the caller and wrappers like irq_get_desc_lock (PATCH_DESCRIPTION/ROOTCAUSE_ANALYSIS).
  - Sinks: irq_put_desc_unlock and *_irqrestore calls clear the state.
  - Propagate into callees when no enabling occurs before the call.
- In callees, identify primitives that unconditionally enable interrupts on exit (guard(raw_spinlock_irq), *_unlock_irq) and distinguish from save/restore variants.

5. Validation & Test Cases
- Positive: Caller does raw_spin_lock_irqsave; calls its_irq_set_vcpu_affinity; callee uses guard(raw_spinlock_irq) on a lock; caller later does irq_put_desc_unlock. Expect a finding highlighting premature interrupt enable (matches PATCH_DESCRIPTION and ROOTCAUSE_ANALYSIS).
- Negative: Same as above but callee uses guard(raw_spinlock) (as per PATCH_DIFF fix). Expect no finding.
- Negative: Caller does raw_spin_lock_irqsave; callee uses raw_spin_lock_irqsave/raw_spin_unlock_irqrestore. Expect no finding due to restore semantics.
- Positive: Caller uses irq_get_desc_lock; callee uses spin_lock_irq/spin_unlock_irq around internal lock. Expect a finding.

- Test harness notes: Ensure interprocedural analysis across at least one call depth and model of RAII guard semantics for guard(raw_spinlock_irq) vs guard(raw_spinlock).

6. Estimated Effort & Priority
High: Requires interprocedural control/dataflow to model IRQ-disabled regions, macro/RAII recognition, and lock semantics.

7. Likely False-Positive Sources & Mitigations
- Unknown or unmodeled wrappers that disable/enable IRQs; mitigate by starting with the explicitly named APIs from PATCH_DESCRIPTION/ROOTCAUSE_ANALYSIS.
- Complex control flow where interrupts are re-disabled after being enabled in the callee; mitigate by checking for explicit re-disable before return.
- Macro indirection obscuring guard semantics; mitigate by recognizing known guard patterns (guard(raw_spinlock_irq), guard(raw_spinlock)) as per PATCH_DIFF.

8. Limitations & Assumptions
- Assumes availability of a recognizable set of IRQ state primitives; only raw_spin_lock_irqsave, guard(raw_spinlock_irq), guard(raw_spinlock), irq_get_desc_lock, and irq_put_desc_unlock are evidenced here.
- Does not determine runtime feasibility beyond static dominance; specific race impacts or memory-safety consequences are not derivable from the provided materials (ROOTCAUSE_ANALYSIS).
- Assumes guard(raw_spinlock_irq) maps to raw_spin_lock_irq/unlock behaviour that unconditionally enables on exit, as described in PATCH_DESCRIPTION/ROOTCAUSE_ANALYSIS.