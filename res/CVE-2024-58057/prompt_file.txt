1. CVE Identifier
CVE-2024-58057

2. Vulnerability Type
Denial of Service (DoS) via CPU-bound workqueue starvation

3. Root Cause Summary
The IDPF driver created all internal workqueues with flags = 0 (CPU-bound per-cpu kworkers). This bound scheduling allowed a high-priority or CPU-hogging userspace process to starve the kworker on the target CPU, delaying driver work items (init, service, mailbox, stats, virtchnl event handling) indefinitely. The prolonged delays led to timeouts, resets, and eventual system crash. The patch corrects this by making these workqueues unbound and reclaim-capable, allowing worker migration to other CPUs and guaranteeing forward progress.

4. Kernel Subsystem Analysis
1) Affected Subsystem:
Intel IDPF network driver (drivers/net/ethernet/intel/idpf)

2) Pre-Patch Flaw:
In idpf_probe(), the driver allocated all workqueues with alloc_workqueue(..., 0, 0, ...), i.e., CPU-bound per-cpu worker-pools. Evidence: pre-patch lines such as “adapter->init_wq = alloc_workqueue("%s-%s-init", 0, 0, ...)” and similarly for serv_wq, mbx_wq, stats_wq, vc_event_wq.

3) Trigger Condition:
A misconfigured or malicious process hogging a specific CPU (e.g., CPU0 via taskset, chrt, renice) starves that CPU’s kworker, while the driver queues its delayed work onto that CPU (default behavior or explicit CPU selection). Patch description demonstrates delays up to 30ms between workqueue_queue_work and workqueue_execute_start under such conditions.

4) Impact Mechanism:
Starvation of driver work items causes performance degradation and timeouts in control paths (service, mailbox, virtchnl events). Accumulated timeouts and delayed completions lead to driver resets and “eventual system crash” as stated in the patch description.

5. Patch Analysis
1) Fix Approach:
Convert all critical driver workqueues to WQ_UNBOUND to decouple them from specific CPUs and add WQ_MEM_RECLAIM to ensure a rescuer and progress under memory pressure.

2) Key Code Changes:
In idpf_probe():
- init_wq: flags changed from 0 to WQ_UNBOUND | WQ_MEM_RECLAIM
- serv_wq: flags changed from 0 to WQ_UNBOUND | WQ_MEM_RECLAIM
- mbx_wq: flags changed from 0 to WQ_UNBOUND | WQ_MEM_RECLAIM
- stats_wq: flags changed from 0 to WQ_UNBOUND | WQ_MEM_RECLAIM
- vc_event_wq: flags changed from 0 to WQ_UNBOUND | WQ_MEM_RECLAIM
These changes allow queued work (e.g., queue_delayed_work(adapter->vc_event_wq, ...)) to execute on any CPU in the NUMA node rather than being tied to a potentially starved CPU.

3) Locking/Concurrency Impact:
No explicit locking changes; concurrency characteristics shift because work may now run on different CPUs. This reduces contention/starvation risk and improves progress guarantees, but does not alter the driver’s existing synchronization primitives (mutexes are initialized separately and unchanged). WQ_MEM_RECLAIM adds a rescuer to ensure forward progress when normal workers are unavailable.

6. Broader Kernel Security Implications
Using CPU-bound workqueues for progress-critical driver tasks can be exploited by local processes to create a trivial DoS via CPU starvation. Converting such workqueues to WQ_UNBOUND (and, where appropriate, WQ_MEM_RECLAIM) is a defensive design that improves resilience against scheduling starvation and system-wide stalls. Other drivers should audit workqueue usage to avoid binding critical work to potentially contended per-cpu workers.