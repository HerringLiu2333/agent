1. CVE Identifier
CVE-2025-39735

2. Vulnerability Type
Integer overflow leading to slab/heap out-of-bounds read via signed-to-unsigned length conversion in diagnostic hex dump.

3. Root Cause Summary
In jfs_xattr.c:ea_get(), when the on-disk extended attribute list size EALIST_SIZE(ea_buf->xattr) differs from ea_size, the code clamps ea_size using clamp_t(int, ...) with an unvalidated upper bound derived from EALIST_SIZE. If EALIST_SIZE exceeds INT_MAX, the clamp’s upper bound overflows when treated as int, producing a negative “size”. That negative “size” is then passed to print_hex_dump(), which converts it to a large size_t and iterates far beyond the end of the buffer, causing an out-of-bounds read in hex_dump_to_buffer(). The root cause is missing validation of EALIST_SIZE(ea_buf->xattr) before using it as an int upper bound and passing the resulting (potentially negative) length into printing routines.

4. Kernel Subsystem Analysis
1) Affected Subsystem:
JFS filesystem extended attribute handling (fs/jfs/jfs_xattr.c), specifically ea_get() logging path.

2) Pre-Patch Flaw:
At the “size_check” label in ea_get(), the code performs:
“int size = clamp_t(int, ea_size, 0, EALIST_SIZE(ea_buf->xattr));” followed by print_hex_dump(..., size, ...).
There is no check that EALIST_SIZE(ea_buf->xattr) fits within INT_MAX, so a too-large value overflows the int upper bound in clamp_t, producing a negative “size” used by print_hex_dump.

3) Trigger Condition:
- An invalid or corrupted on-disk xattr list causes EALIST_SIZE(ea_buf->xattr) != ea_size and EALIST_SIZE(ea_buf->xattr) > INT_MAX.
- The code enters the “size_check” error path and executes clamp_t(int, ...) with the oversized upper bound, producing a negative “size”.
- That negative “size” is passed to print_hex_dump(), which treats it as a huge unsigned length.

4) Impact Mechanism:
print_hex_dump() iterates up to the (huge) len and repeatedly calls hex_dump_to_buffer(ptr + i, linelen, ...) with i growing toward/over the end of the actual buffer; hex_dump_to_buffer then performs “ch = ptr[j]” for j < linelen, resulting in slab-out-of-bounds reads. This can cause kernel memory disclosure and/or crashes.

5. Patch Analysis
1) Fix Approach:
Input validation: explicitly guard against EALIST_SIZE(ea_buf->xattr) > INT_MAX before performing clamp_t and before calling print_hex_dump().

2) Key Code Changes:
- Added:
“if (unlikely(EALIST_SIZE(ea_buf->xattr) > INT_MAX)) { printk(... 'size too large' ...); } else { int size = clamp_t(int, ea_size, 0, EALIST_SIZE(ea_buf->xattr)); printk(...); print_hex_dump(..., size, ...); }”
- This prevents integer overflow of the clamp upper bound and avoids passing a negative “size” to print_hex_dump() when the xattr size exceeds INT_MAX.

3) Locking/Concurrency Impact:
None. The change only adds bounds checks and conditional logging; no locks or ordering were modified.

6. Broader Kernel Security Implications
- Diagnostic/logging code that consumes lengths from untrusted on-disk metadata must validate those lengths before using them, especially when crossing signed/unsigned type boundaries.
- Using clamp_t with a destination type narrower than the source/limit (int vs. potentially large u32) is dangerous; prefer size_t for sizes or validate ranges before clamping.
- Similar patterns elsewhere (hex dumps or buffer printers) should ensure inputs cannot become negative or exceed safe bounds to avoid OOB reads/writes triggered by corrupted filesystem data.