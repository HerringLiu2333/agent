1. Plan Summary
Detect missing removal (deregistration) of CPU latency PM QoS requests on error/cleanup paths before freeing or tearing down the owning driver structures, preventing dangling list entries and use-after-free as seen in isys_probe.

2. Detection Steps
1) Step 1: Identify candidate functions that manage CPU latency PM QoS requests — look for functions referencing a request object (e.g., a struct field like pm_qos) or calling cpu_latency_qos_* APIs, especially in probe-like initializers (e.g., functions named *probe returning int) per the isys_probe context in [PATCH_DIFF]. Mitigate false positives by focusing on functions within driver code that perform multi-step initialization with goto error labels or early returns.

2) Step 2: Identify the specific request instance to track — find the base object whose field is passed by address to cpu_latency_qos_remove_request (e.g., &obj->pm_qos as shown in [PATCH_DIFF]) and treat that field as a resource requiring deregistration. Reduce FPs by restricting to exact field-object relationships (field address-of expressions) and maintaining alias consistency for that object within the function.

3) Step 3: Locate error-unwind and cleanup paths — find gotos to labels and returns that represent failure exits (e.g., the out_remove_pkg_dir_shared_buffer label in [PATCH_DIFF], negative errno returns). Mitigate FPs by focusing on error exits that are preceded by partial initialization and resource frees (see Step 4).

4) Step 4: Detect evidence of partial initialization before the error point — along the path to each error label, look for other resource teardown calls (e.g., free_fw_msg_bufs, remove_shared_buffer, ipu6_cpd_free_pkg_dir per [PATCH_DIFF]) to confirm we are in a teardown phase after prior setup. This matches the root cause that PM QoS remained registered while other structures were freed ([ROOTCAUSE_ANALYSIS]), and reduces FPs by avoiding paths that never progressed past early parameter checks.

5) Step 5: Check for missing deregistration — for each error/cleanup path that tears down resources of the owning object, verify a call to cpu_latency_qos_remove_request is present for the same request object prior to any frees/teardown or function exit. This directly maps to the root cause where the request remained registered and caused list corruption ([ROOTCAUSE_ANALYSIS], [PATCH_DESCRIPTION]).

6) Step 6: Enforce correct ordering — if both cpu_latency_qos_remove_request and any frees/teardown exist on a path, ensure cpu_latency_qos_remove_request post-dominates the setup point and dominates subsequent freeing/teardown of the owning object, mirroring the fix that added removal before other frees ([PATCH_DIFF]). Reduce FPs by only flagging when order is provably incorrect along at least one realizable path.

7) Step 7: Consider implicit frees of the containing object — flag paths that return from probe-like initializers with error without deregistering the request if the function also undoes other allocations, because the caller will tear down the container, yielding a dangling list node (per [ROOTCAUSE_ANALYSIS]). Mitigate FPs by requiring the function to have performed at least one non-trivial allocation/initialization earlier or to call other cleanup functions at the error point.

8) Step 8: Strengthen evidence of registration — treat any use of the request in APIs other than remove (e.g., cpu_latency_qos_update_request cited in the crash trace in [PATCH_DESCRIPTION]) within the function as evidence that the request could be active on error paths. If such evidence exists, require deregistration; else, lower severity but still report if other teardown strongly suggests the object lifetime is ending.

9) Step 9: Scope to the same request object — ensure the remove call, if present, targets the same exact field instance (&obj->pm_qos) as would be left dangling; do not consider removes on other objects sufficient. This reduces FPs where unrelated requests are properly handled.

10) Step 10: Highlight multi-label unwinds — in functions with multiple error labels, ensure each path that reaches a teardown label (like out_remove_pkg_dir_shared_buffer in [PATCH_DIFF]) invokes cpu_latency_qos_remove_request before any frees and before function exit. This addresses bugs where some but not all error labels remove the request (a common source of partial fixes).

3. Target Elements
- Functions: probe-like initializers (e.g., functions named *probe returning int), other initializer functions with multi-step setup and goto-based unwinds.
- Call sites: cpu_latency_qos_remove_request; other cpu_latency_qos_* or pm_qos_* calls as evidence of request activity.
- Struct field accesses: address-of operations on fields representing the PM QoS request (e.g., &obj->pm_qos).
- Control-flow constructs: goto-based error labels, early returns with negative error codes.
- Resource teardown calls: functions with free/remove/release semantics (e.g., free_fw_msg_bufs, remove_shared_buffer, ipu6_cpd_free_pkg_dir from [PATCH_DIFF]).

4. Dataflow / Taint Considerations
- Track the specific request resource: the field address-of (&obj->pm_qos) and its base object throughout the function.
- Path-sensitive reachability: from post-initialization points to error labels, ensure cpu_latency_qos_remove_request is invoked before any deallocation/teardown of the base object or exit.
- Dominance/order: cpu_latency_qos_remove_request should dominate frees/teardown on all such error paths; absence or wrong order is a hit.

5. Validation & Test Cases
- Positive: A probe-like function that references obj->pm_qos (e.g., later used/updated), hits an error label that calls free_fw_msg_bufs/remove_shared_buffer/ipu6_cpd_free_pkg_dir, but does not call cpu_latency_qos_remove_request before those frees or return. Expect a report for missing deregistration leading to dangling pm_qos entry (as per [ROOTCAUSE_ANALYSIS] and fixed in [PATCH_DIFF]).
- Negative: Same function with cpu_latency_qos_remove_request(&obj->pm_qos) inserted at the error label before any frees/teardown (as in [PATCH_DIFF]). Expect no report.
- Negative: An initializer function that never references or registers a pm_qos request and only frees unrelated resources. Expect no report.
- Test harness notes: Ensure CFG/path-sensitivity over goto-based unwinds; include aliasing where obj is passed through local pointers but remains the same base.

6. Estimated Effort & Priority
Medium: Requires path-sensitive analysis of cleanup paths and resource-order validation, but targets a narrow, well-scoped API pattern (cpu_latency_qos_*).

7. Likely False-Positive Sources & Mitigations
- Cleanup delegated to a common helper not visible in the same function: mitigate by restricting to intra-procedural guarantees and flagging with lower confidence if a helper is called but its body is unavailable.
- Functions that reference the pm_qos field but never register the request: mitigate by raising severity only when other teardown work indicates partial init, or when non-remove QoS APIs are called.
- Misclassification of frees not tied to the containing object: mitigate by correlating the base object whose pm_qos field is tracked with arguments of free/remove helpers when possible.

8. Limitations & Assumptions
- The exact registration API name for CPU latency PM QoS requests is not provided; the checker infers possible registration from context (use of pm_qos field and presence of teardown) and known remove API from [PATCH_DIFF].
- It assumes the request is embedded as a struct field (e.g., obj->pm_qos) and that cpu_latency_qos_remove_request is the required deregistration, per [ROOTCAUSE_ANALYSIS] and [PATCH_DIFF].
- Inter-procedural cleanup (in other functions) is not fully modeled; analysis is primarily intra-procedural within the initializer/probe function.
- The checker focuses on the CPU latency PM QoS class described; it does not generalize to other global registration types beyond the evidence provided.