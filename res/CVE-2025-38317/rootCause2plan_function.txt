1. Plan Summary
Detect kernel debugfs-like write handlers that allocate a fixed-size heap buffer and copy user data into it using an unbounded count, missing a prior check that count ≤ buffer size (heap overflow as in CVE-2025-38317).

2. Detection Steps
1) Step 1: Identify candidate functions handling user writes. Signals: functions with parameters like “const char __user *user_buf” and “size_t count” and a call to copy_from_user; this maps to ath12k_write_htt_stats_type in [FUNCTION_CONTENT], and requiring copy_from_user reduces FPs to relevant handlers.
2) Step 2: Find a fixed-size heap allocation for the destination buffer. Signals: kzalloc/kmalloc with a constant or const-int “size” assigned to a pointer (e.g., char *buf), matching [FUNCTION_CONTENT]; require that this buffer is later used as copy_from_user’s destination to avoid unrelated allocations.
3) Step 3: Detect copy_from_user where the third argument is the unvalidated count parameter. Signals: copy_from_user(dest=buf, src=user_buf, len=count or a value dataflow-equivalent to count as per [FUNCTION_CONTENT]; exclude cases where len is a literal or known ≤ size to reduce FPs.
4) Step 4: Verify there is no guard that enforces count ≤ size before the copy. Signals: absence of a dominating condition like “if (count > size) return …” or equivalent clamping (e.g., count = min(count, size)); this maps directly to the missing check described in [PATCH_DIFF] and [ROOTCAUSE_ANALYSIS], and recognizing common clamping patterns mitigates FPs.
5) Step 5: Ensure the buffer size is independent of count. Signals: kzalloc size is a constant or const variable (e.g., 32 in [FUNCTION_CONTENT]) not derived from count; exclude cases where allocation size equals or depends on count to avoid safe-by-construction scenarios.
6) Step 6: Confirm allocation and copy occur within the same function scope. Signals: both kzalloc and copy_from_user are in the same function and control-flow region as seen in [FUNCTION_CONTENT]; this tightens the match to the root cause and avoids cross-function analysis FPs.
7) Step 7: Check that the destination to copy_from_user aliases the allocated buffer directly. Signals: the first argument to copy_from_user is the same variable (buf) and not a separately sized structure; alias confirmation prevents misattribution.
8) Step 8: Look for subsequent parsing of the buffer (e.g., sscanf on buf) as a confidence booster. Signals: sscanf on buf parsing multiple integers like in [FUNCTION_CONTENT]; treat this as optional evidence to prioritize likely debugfs handlers and mitigate incidental matches.
9) Step 9: Identify return of the original count as an indicator of unbounded handling. Signals: “return count;” at function end as in [FUNCTION_CONTENT]; use this as ancillary evidence to increase confidence, not as a strict requirement.
10) Step 10: Emit a finding when an unbounded count flows into copy_from_user for a fixed-size heap buffer with no preceding bound check. Signals: steps 1–7 satisfied and step 4 fails; this precisely matches the heap overflow root cause described in [ROOTCAUSE_ANALYSIS] and [PATCH_DESCRIPTION], and the combined criteria reduce false positives.

3. Target Elements
- Functions that accept “const char __user*” and “size_t count” parameters (write handlers).
- Heap allocation sites (kzalloc/kmalloc) with fixed sizes.
- Calls to copy_from_user using the allocated buffer as destination.
- Conditions/comparisons guarding count vs. buffer size (or lack thereof).
- Dataflow relations between count parameter and copy length argument.
- Subsequent uses of the buffer (e.g., sscanf) as contextual evidence.

4. Dataflow / Taint Considerations
- Track taint from the function parameter “count” to the third argument of copy_from_user.
- Confirm the destination argument of copy_from_user aliases the buffer from the fixed-size allocation.
- Perform dominance/guard analysis to ensure no prior clamping or comparison establishes count ≤ size.
- Treat transformations like min(count, size) or reassigning count to a bounded value as sanitization.

5. Validation & Test Cases
- Positive: Pre-patch ath12k_write_htt_stats_type from [FUNCTION_CONTENT] (fixed 32-byte kzalloc, copy_from_user with count, no length check) should be flagged.
- Negative: Patched version from [PATCH_DIFF] (explicit “if (count > size) return -EINVAL;” before copy) should not be flagged.
- Negative: A variant where count is clamped (e.g., count = min(count, size)) or allocation uses count (buf = kmalloc(count, …); copy_from_user(buf, …, count)) should not be flagged.
- Test harness notes: Use small kernel-like stubs with the exact patterns, ensuring the checker can see allocation, copy, and guards within the same function.

6. Estimated Effort & Priority
High; pattern-based plus local dataflow and dominance checks in kernel code are feasible and valuable due to the severity of heap overflows.

7. Likely False-Positive Sources & Mitigations
- Hidden or macro-based guards that clamp count: mitigate by dominance analysis and recognizing common min/clamp idioms.
- Copy size indirectly bounded via helper functions: mitigate by tracing simple dataflow and recognizing sanitized assignments.
- Allocations that resize buffers before copy: mitigate by requiring fixed-size allocation and same-scope aliasing to the destination.
- Non-kernel contexts mimicking signatures: mitigate by requiring copy_from_user usage and __user pointers.

8. Limitations & Assumptions
- Assumes “count” is user-controlled and not bounded elsewhere outside the function; cross-function sanitization may be missed.
- Focuses on heap-based fixed-size buffers; stack-based overflows are not covered by this plan.
- Does not attempt to prove runtime invariants (e.g., typical write sizes); relies on structural checks.
- Assumes recognition of copy_from_user and simple clamp idioms; complex macro indirections or wrappers may evade detection.