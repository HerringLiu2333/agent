You are a senior static-analysis engineer and CodeQL design expert.
Task: Based only on the supplied materials, produce a human-readable detection plan (natural-language) for a CodeQL checker that would detect the same class of vulnerability described. DO NOT produce any query code or pseudocode — the output must be purely natural language steps and rationale.

Rules:
1. Only use evidence contained in the sections labeled [PATCH_DESCRIPTION], [PATCH_DIFF], [FUNCTION_CONTENT], and [ROOTCAUSE_ANALYSIS]. Do not invent facts.
2. The plan must be a step-by-step detection strategy in natural language (numbered steps). No code, no query snippets, no regex, no domain-specific language.
3. Each step must state: objective, signals to look for (AST/semantic patterns expressed conceptually), why it maps to the root cause, and how to reduce false positives.
4. Include a short test/validation strategy (what sample cases to run and expected outcomes).
5. List limitations and assumptions (what is Not determinable from inputs).
6. Keep the plan concise: overall ≤ 12 numbered steps and each step ≤ 2 concise sentences. Use bullets where helpful.
7. If information required to design an accurate checker is missing, state it explicitly under "Limitations & Assumptions".

[META]
CVE_NAME: CVE-2025-38255

[INFO]
[PATCH_DESCRIPTION]
    lib/group_cpus: fix NULL pointer dereference from group_cpus_evenly()
    While testing null_blk with configfs, echo 0 > poll_queues will trigger
    following panic:
    
    BUG: kernel NULL pointer dereference, address: 0000000000000010
    Oops: Oops: 0000 [#1] SMP NOPTI
    CPU: 27 UID: 0 PID: 920 Comm: bash Not tainted 6.15.0-02023-gadbdb95c8696-dirty #1238 PREEMPT(undef)
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.1-2.fc37 04/01/2014
    RIP: 0010:__bitmap_or+0x48/0x70
    Call Trace:
     <TASK>
     __group_cpus_evenly+0x822/0x8c0
     group_cpus_evenly+0x2d9/0x490
     blk_mq_map_queues+0x1e/0x110
     null_map_queues+0xc9/0x170 [null_blk]
     blk_mq_update_queue_map+0xdb/0x160
     blk_mq_update_nr_hw_queues+0x22b/0x560
     nullb_update_nr_hw_queues+0x71/0xf0 [null_blk]
     nullb_device_poll_queues_store+0xa4/0x130 [null_blk]
     configfs_write_iter+0x109/0x1d0
     vfs_write+0x26e/0x6f0
     ksys_write+0x79/0x180
     __x64_sys_write+0x1d/0x30
     x64_sys_call+0x45c4/0x45f0
     do_syscall_64+0xa5/0x240
     entry_SYSCALL_64_after_hwframe+0x76/0x7e
    
    Root cause is that numgrps is set to 0, and ZERO_SIZE_PTR is returned from
    kcalloc(), and later ZERO_SIZE_PTR will be deferenced.
    
    Fix the problem by checking numgrps first in group_cpus_evenly(), and
    return NULL directly if numgrps is zero.

[PATCH_DIFF]
    @@ -352,6 +352,9 @@ struct cpumask *group_cpus_evenly(unsigned int numgrps)
     	int ret = -ENOMEM;
     	struct cpumask *masks = NULL;
     
     +	if (numgrps == 0)
     +		return NULL;
     +
     	if (!zalloc_cpumask_var(&nmsk, GFP_KERNEL))
     		return NULL;

[FUNCTION_CONTENT]
struct cpumask *group_cpus_evenly(unsigned int numgrps)
{
	unsigned int curgrp = 0, nr_present = 0, nr_others = 0;
	cpumask_var_t *node_to_cpumask;
	cpumask_var_t nmsk, npresmsk;
	int ret = -ENOMEM;
	struct cpumask *masks = NULL;

	if (!zalloc_cpumask_var(&nmsk, GFP_KERNEL))
		return NULL;

	if (!zalloc_cpumask_var(&npresmsk, GFP_KERNEL))
		goto fail_nmsk;

	node_to_cpumask = alloc_node_to_cpumask();
	if (!node_to_cpumask)
		goto fail_npresmsk;

	masks = kcalloc(numgrps, sizeof(*masks), GFP_KERNEL);
	if (!masks)
		goto fail_node_to_cpumask;

	build_node_to_cpumask(node_to_cpumask);

	/*
	 * Make a local cache of 'cpu_present_mask', so the two stages
	 * spread can observe consistent 'cpu_present_mask' without holding
	 * cpu hotplug lock, then we can reduce deadlock risk with cpu
	 * hotplug code.
	 *
	 * Here CPU hotplug may happen when reading `cpu_present_mask`, and
	 * we can live with the case because it only affects that hotplug
	 * CPU is handled in the 1st or 2nd stage, and either way is correct
	 * from API user viewpoint since 2-stage spread is sort of
	 * optimization.
	 */
	cpumask_copy(npresmsk, data_race(cpu_present_mask));

	/* grouping present CPUs first */
	ret = __group_cpus_evenly(curgrp, numgrps, node_to_cpumask,
				  npresmsk, nmsk, masks);
	if (ret < 0)
		goto fail_build_affinity;
	nr_present = ret;

	/*
	 * Allocate non present CPUs starting from the next group to be
	 * handled. If the grouping of present CPUs already exhausted the
	 * group space, assign the non present CPUs to the already
	 * allocated out groups.
	 */
	if (nr_present >= numgrps)
		curgrp = 0;
	else
		curgrp = nr_present;
	cpumask_andnot(npresmsk, cpu_possible_mask, npresmsk);
	ret = __group_cpus_evenly(curgrp, numgrps, node_to_cpumask,
				  npresmsk, nmsk, masks);
	if (ret >= 0)
		nr_others = ret;

 fail_build_affinity:
	if (ret >= 0)
		WARN_ON(nr_present + nr_others < numgrps);

 fail_node_to_cpumask:
	free_node_to_cpumask(node_to_cpumask);

 fail_npresmsk:
	free_cpumask_var(npresmsk);

 fail_nmsk:
	free_cpumask_var(nmsk);
	if (ret < 0) {
		kfree(masks);
		return NULL;
	}
	return masks;
}



[ROOTCAUSE_ANALYSIS]
1. CVE Identifier
CVE-2025-38255

2. Vulnerability Type
NULL/invalid pointer dereference due to zero-sized allocation (ZERO_SIZE_PTR misuse)

3. Root Cause Summary
group_cpus_evenly() failed to validate that numgrps was non-zero before allocating the masks array, allowing kcalloc(0, ...) to return ZERO_SIZE_PTR, which is non-NULL and thus not caught by the existing NULL check. The function then passed this invalid pointer to __group_cpus_evenly(), which performed cpumask operations (e.g., __bitmap_or) that dereferenced the pointer, causing a kernel oops. The flawed pre-patch logic was the absence of a guard for numgrps == 0 and reliance on a “!masks” check that does not detect ZERO_SIZE_PTR.

4. Kernel Subsystem Analysis
1) Affected Subsystem:
lib/group_cpus (CPU mask grouping utility used by block layer mapping)

2) Pre-Patch Flaw:
- masks = kcalloc(numgrps, sizeof(*masks), GFP_KERNEL) with numgrps == 0 returns ZERO_SIZE_PTR.
- The subsequent check “if (!masks) goto fail_node_to_cpumask;” does not catch ZERO_SIZE_PTR, and the code proceeds to use masks.
- __group_cpus_evenly() expects a valid masks array and performs cpumask operations that dereference masks entries.

3) Trigger Condition:
Writing 0 to poll_queues via configfs in null_blk (echo 0 > poll_queues) propagates numgrps == 0 into group_cpus_evenly(), leading to a call chain through blk_mq_map_queues and ultimately __group_cpus_evenly with an invalid masks pointer.

4) Impact Mechanism:
ZERO_SIZE_PTR is dereferenced during bitmap/cpumask operations (observed at __bitmap_or+0x48), resulting in a kernel NULL pointer dereference (address 0x10) and system crash (DoS).

5. Patch Analysis
1) Fix Approach:
Introduce explicit input validation: early return if numgrps == 0 to avoid zero-sized allocation and subsequent invalid pointer use.

2) Key Code Changes:
- Added at function entry:
  “if (numgrps == 0) return NULL;”
This prevents kcalloc(numgrps, ...) from being called with numgrps == 0 and avoids passing ZERO_SIZE_PTR to __group_cpus_evenly().

3) Locking/Concurrency Impact:
No changes to locking or concurrency. Existing logic around cpu_present_mask copying (data_race) remains unchanged; the fix is purely an input validation and memory safety correction.

6. Broader Kernel Security Implications
- Prevents a user-triggerable kernel crash via configuration paths that can set group count to zero, reducing denial-of-service risk in block-mq users and other callers of group_cpus_evenly().
- Highlights the importance of validating size/count parameters before allocations to avoid ZERO_SIZE_PTR hazards.
- Encourages consistent input validation across helper utilities in lib/ to harden against similar invalid-pointer dereference issues.

[REQUEST]
Produce a detection plan for a CodeQL-based static checker that would detect similar pre-patch flaws.
Requirements for the plan:
- High-level detection goal (1–2 lines).
- A numbered list of detection steps (objective, conceptual AST/semantic signals, FP mitigation).
- Types of program elements to target (functions, call sites, allocation sites, condition checks, lock boundaries, function return-value uses, etc.).
- Dataflow/taint patterns to consider (if applicable), described conceptually.
- Minimal test cases to validate the checker (positive/negative examples).
- Estimated effort/priority (low/medium/high) and likely false-positive sources.
- A short "Limitations & Assumptions" block.

OUTPUT FORMAT (produce exactly this structure; no extra text):
1. Plan Summary
{one-line summary}

2. Detection Steps
1) Step 1: {objective — conceptual signals — FP mitigation}
2) Step 2: {objective — conceptual signals — FP mitigation}
...
(narrow to ≤12 steps)

3. Target Elements
- {list of element types to inspect}

4. Dataflow / Taint Considerations
- {conceptual taint/flow rules to track}

5. Validation & Test Cases
- Positive: {brief}
- Negative: {brief}
- Test harness notes: {brief}

6. Estimated Effort & Priority
{low/medium/high}

7. Likely False-Positive Sources & Mitigations
- {list}

8. Limitations & Assumptions
- {explicit missing info or assumptions}

CONSTRAINTS:
- Do not emit any CodeQL, SQL, pseudocode, or query fragments.
- Keep answers evidence-based and reference which provided field supported each major choice (e.g., “based on [PATCH_DIFF] hunk that adds X”).
- Output must be machine-parseable: keep the exact numbered section headings as above.