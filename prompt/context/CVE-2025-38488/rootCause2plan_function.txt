You are a senior static-analysis engineer and CodeQL design expert.
Task: Based only on the supplied materials, produce a human-readable detection plan (natural-language) for a CodeQL checker that would detect the same class of vulnerability described. DO NOT produce any query code or pseudocode — the output must be purely natural language steps and rationale.

Rules:
1. Only use evidence contained in the sections labeled [PATCH_DESCRIPTION], [PATCH_DIFF], [FUNCTION_CONTENT], and [ROOTCAUSE_ANALYSIS]. Do not invent facts.
2. The plan must be a step-by-step detection strategy in natural language (numbered steps). No code, no query snippets, no regex, no domain-specific language.
3. Each step must state: objective, signals to look for (AST/semantic patterns expressed conceptually), why it maps to the root cause, and how to reduce false positives.
4. Include a short test/validation strategy (what sample cases to run and expected outcomes).
5. List limitations and assumptions (what is Not determinable from inputs).
6. Keep the plan concise: overall ≤ 12 numbered steps and each step ≤ 2 concise sentences. Use bullets where helpful.
7. If information required to design an accurate checker is missing, state it explicitly under "Limitations & Assumptions".

[META]
CVE_NAME: CVE-2025-38488

[INFO]
[PATCH_DESCRIPTION]
    smb: client: fix use-after-free in crypt_message when using async crypto
    The CVE-2024-50047 fix removed asynchronous crypto handling from
    crypt_message(), assuming all crypto operations are synchronous.
    However, when hardware crypto accelerators are used, this can cause
    use-after-free crashes:
    
      crypt_message()
        // Allocate the creq buffer containing the req
        creq = smb2_get_aead_req(..., &req);
    
        // Async encryption returns -EINPROGRESS immediately
        rc = enc ? crypto_aead_encrypt(req) : crypto_aead_decrypt(req);
    
        // Free creq while async operation is still in progress
        kvfree_sensitive(creq, ...);
    
    Hardware crypto modules often implement async AEAD operations for
    performance. When crypto_aead_encrypt/decrypt() returns -EINPROGRESS,
    the operation completes asynchronously. Without crypto_wait_req(),
    the function immediately frees the request buffer, leading to crashes
    when the driver later accesses the freed memory.
    
    This results in a use-after-free condition when the hardware crypto
    driver later accesses the freed request structure, leading to kernel
    crashes with NULL pointer dereferences.
    
    The issue occurs because crypto_alloc_aead() with mask=0 doesn't
    guarantee synchronous operation. Even without CRYPTO_ALG_ASYNC in
    the mask, async implementations can be selected.
    
    Fix by restoring the async crypto handling:
    - DECLARE_CRYPTO_WAIT(wait) for completion tracking
    - aead_request_set_callback() for async completion notification
    - crypto_wait_req() to wait for operation completion
    
    This ensures the request buffer isn't freed until the crypto operation
    completes, whether synchronous or asynchronous, while preserving the
    CVE-2024-50047 fix.

[PATCH_DIFF]
     @@ -4316,6 +4316,7 @@ crypt_message(struct TCP_Server_Info *server, int num_rqst,
      	u8 key[SMB3_ENC_DEC_KEY_SIZE];
      	struct aead_request *req;
      	u8 *iv;
     +	DECLARE_CRYPTO_WAIT(wait);
      	unsigned int crypt_len = le32_to_cpu(tr_hdr->OriginalMessageSize);
      	void *creq;
      	size_t sensitive_size;
     @@ -4366,7 +4367,11 @@ crypt_message(struct TCP_Server_Info *server, int num_rqst,
      	aead_request_set_crypt(req, sg, sg, crypt_len, iv);
      	aead_request_set_ad(req, assoc_data_len);
     
     -	rc = enc ? crypto_aead_encrypt(req) : crypto_aead_decrypt(req);
     +	aead_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG,
     +				  crypto_req_done, &wait);
     +
     +	rc = crypto_wait_req(enc ? crypto_aead_encrypt(req)
     +				: crypto_aead_decrypt(req), &wait);
     
      	if (!rc && enc)
      		memcpy(&tr_hdr->Signature, sign, SMB2_SIGNATURE_SIZE);

[FUNCTION_CONTENT]
static int
crypt_message(struct TCP_Server_Info *server, int num_rqst,
	      struct smb_rqst *rqst, int enc, struct crypto_aead *tfm)
{
	struct smb2_transform_hdr *tr_hdr =
		(struct smb2_transform_hdr *)rqst[0].rq_iov[0].iov_base;
	unsigned int assoc_data_len = sizeof(struct smb2_transform_hdr) - 20;
	int rc = 0;
	struct scatterlist *sg;
	u8 sign[SMB2_SIGNATURE_SIZE] = {};
	u8 key[SMB3_ENC_DEC_KEY_SIZE];
	struct aead_request *req;
	u8 *iv;
	unsigned int crypt_len = le32_to_cpu(tr_hdr->OriginalMessageSize);
	void *creq;
	size_t sensitive_size;

	rc = smb2_get_enc_key(server, le64_to_cpu(tr_hdr->SessionId), enc, key);
	if (rc) {
		cifs_server_dbg(FYI, "%s: Could not get %scryption key. sid: 0x%llx\n", __func__,
			 enc ? "en" : "de", le64_to_cpu(tr_hdr->SessionId));
		return rc;
	}

	if ((server->cipher_type == SMB2_ENCRYPTION_AES256_CCM) ||
		(server->cipher_type == SMB2_ENCRYPTION_AES256_GCM))
		rc = crypto_aead_setkey(tfm, key, SMB3_GCM256_CRYPTKEY_SIZE);
	else
		rc = crypto_aead_setkey(tfm, key, SMB3_GCM128_CRYPTKEY_SIZE);

	if (rc) {
		cifs_server_dbg(VFS, "%s: Failed to set aead key %d\n", __func__, rc);
		return rc;
	}

	rc = crypto_aead_setauthsize(tfm, SMB2_SIGNATURE_SIZE);
	if (rc) {
		cifs_server_dbg(VFS, "%s: Failed to set authsize %d\n", __func__, rc);
		return rc;
	}

	creq = smb2_get_aead_req(tfm, rqst, num_rqst, sign, &iv, &req, &sg,
				 &sensitive_size);
	if (IS_ERR(creq))
		return PTR_ERR(creq);

	if (!enc) {
		memcpy(sign, &tr_hdr->Signature, SMB2_SIGNATURE_SIZE);
		crypt_len += SMB2_SIGNATURE_SIZE;
	}

	if ((server->cipher_type == SMB2_ENCRYPTION_AES128_GCM) ||
	    (server->cipher_type == SMB2_ENCRYPTION_AES256_GCM))
		memcpy(iv, (char *)tr_hdr->Nonce, SMB3_AES_GCM_NONCE);
	else {
		iv[0] = 3;
		memcpy(iv + 1, (char *)tr_hdr->Nonce, SMB3_AES_CCM_NONCE);
	}

	aead_request_set_tfm(req, tfm);
	aead_request_set_crypt(req, sg, sg, crypt_len, iv);
	aead_request_set_ad(req, assoc_data_len);

	rc = enc ? crypto_aead_encrypt(req) : crypto_aead_decrypt(req);

	if (!rc && enc)
		memcpy(&tr_hdr->Signature, sign, SMB2_SIGNATURE_SIZE);

	kvfree_sensitive(creq, sensitive_size);
	return rc;
}



[ROOTCAUSE_ANALYSIS]
1. CVE Identifier
CVE-2025-38488

2. Vulnerability Type
Use-after-free due to missing asynchronous crypto completion handling (race between freeing request buffer and AEAD completion)

3. Root Cause Summary
- The function crypt_message() assumed AEAD operations are always synchronous and freed the request buffer immediately after invoking crypto_aead_encrypt()/crypto_aead_decrypt().
- When an async AEAD implementation is selected (e.g., hardware accelerator), these calls can return -EINPROGRESS and complete later, but the code did not set a callback or wait for completion.
- As a result, the allocated request buffer (creq) holding the aead_request and associated memory was freed while the crypto operation was still in progress, leading to use-after-free by the crypto driver.

4. Kernel Subsystem Analysis
1) Affected Subsystem:
- SMB client (CIFS) encryption/decryption path in the Linux kernel, function crypt_message().

2) Pre-Patch Flaw:
- After preparing the AEAD request, the code executed:
  - rc = enc ? crypto_aead_encrypt(req) : crypto_aead_decrypt(req);
  - kvfree_sensitive(creq, sensitive_size);
- It neither set an async callback via aead_request_set_callback() nor waited via crypto_wait_req(), incorrectly assuming synchronous completion.

3) Trigger Condition:
- Use of a crypto AEAD implementation that completes asynchronously (e.g., hardware crypto accelerators) causing crypto_aead_encrypt()/decrypt() to return -EINPROGRESS.
- This can occur regardless of the mask used in crypto_alloc_aead(), since mask=0 does not guarantee synchronous algorithms.

4) Impact Mechanism:
- The in-flight crypto operation later accesses the aead_request and associated memory that was already freed (creq), resulting in a use-after-free.
- This manifests as kernel crashes (e.g., NULL pointer dereferences) and potential memory corruption.

5. Patch Analysis
1) Fix Approach:
- Restore proper asynchronous crypto handling by registering a completion callback and waiting for completion before freeing the request buffer.
- Ensure the function blocks until the AEAD operation completes, whether it is synchronous or asynchronous.

2) Key Code Changes:
- Added DECLARE_CRYPTO_WAIT(wait) to manage completion wait state.
- Added aead_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG, crypto_req_done, &wait) to receive completion notifications and handle backlog.
- Replaced direct invocation with a waited call:
  - rc = crypto_wait_req(enc ? crypto_aead_encrypt(req) : crypto_aead_decrypt(req), &wait);
- These changes ensure kvfree_sensitive(creq, sensitive_size) runs only after the crypto operation has completed.

3) Locking/Concurrency Impact:
- No new spinlocks/mutexes; instead, uses the crypto API’s completion/wait mechanism to serialize freeing memory with operation completion.
- Eliminates the race window between async completion and buffer lifetime by ordering the free after completion notification.
- CRYPTO_TFM_REQ_MAY_BACKLOG allows proper queuing behavior without introducing new deadlocks or contention.

6. Broader Kernel Security Implications
- Kernel users of the crypto API must not assume synchronous operation; they must always handle possible asynchronous completion with callbacks and waits.
- Failing to wait for async completion commonly leads to lifetime bugs (use-after-free) across subsystems integrating with hardware-accelerated crypto.
- The fix illustrates the correct pattern: set callback + crypto_wait_req() to ensure safe memory lifetimes and robust behavior regardless of the selected crypto implementation.

[REQUEST]
Produce a detection plan for a CodeQL-based static checker that would detect similar pre-patch flaws.
Requirements for the plan:
- High-level detection goal (1–2 lines).
- A numbered list of detection steps (objective, conceptual AST/semantic signals, FP mitigation).
- Types of program elements to target (functions, call sites, allocation sites, condition checks, lock boundaries, function return-value uses, etc.).
- Dataflow/taint patterns to consider (if applicable), described conceptually.
- Minimal test cases to validate the checker (positive/negative examples).
- Estimated effort/priority (low/medium/high) and likely false-positive sources.
- A short "Limitations & Assumptions" block.

OUTPUT FORMAT (produce exactly this structure; no extra text):
1. Plan Summary
{one-line summary}

2. Detection Steps
1) Step 1: {objective — conceptual signals — FP mitigation}
2) Step 2: {objective — conceptual signals — FP mitigation}
...
(narrow to ≤12 steps)

3. Target Elements
- {list of element types to inspect}

4. Dataflow / Taint Considerations
- {conceptual taint/flow rules to track}

5. Validation & Test Cases
- Positive: {brief}
- Negative: {brief}
- Test harness notes: {brief}

6. Estimated Effort & Priority
{low/medium/high}

7. Likely False-Positive Sources & Mitigations
- {list}

8. Limitations & Assumptions
- {explicit missing info or assumptions}

CONSTRAINTS:
- Do not emit any CodeQL, SQL, pseudocode, or query fragments.
- Keep answers evidence-based and reference which provided field supported each major choice (e.g., “based on [PATCH_DIFF] hunk that adds X”).
- Output must be machine-parseable: keep the exact numbered section headings as above.