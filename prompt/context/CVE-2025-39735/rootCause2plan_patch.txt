You are a senior static-analysis engineer and CodeQL design expert.
Task: Based only on the supplied materials, produce a human-readable detection plan (natural-language) for a CodeQL checker that would detect the same class of vulnerability described. DO NOT produce any query code or pseudocode — the output must be purely natural language steps and rationale.

Rules:
1. Only use evidence contained in the sections labeled [PATCH_DESCRIPTION], [PATCH_DIFF], and [ROOTCAUSE_ANALYSIS]. Do not invent facts.
2. The plan must be a step-by-step detection strategy in natural language (numbered steps). No code, no query snippets, no regex, no domain-specific language.
3. Each step must state: objective, signals to look for (AST/semantic patterns expressed conceptually), why it maps to the root cause, and how to reduce false positives.
4. Include a short test/validation strategy (what sample cases to run and expected outcomes).
5. List limitations and assumptions (what is Not determinable from inputs).
6. Keep the plan concise: overall ≤ 12 numbered steps and each step ≤ 2 concise sentences. Use bullets where helpful.
7. If information required to design an accurate checker is missing, state it explicitly under "Limitations & Assumptions".

[META]
CVE_NAME: CVE-2025-39735

[INFO]
[PATCH_DESCRIPTION]
    jfs: fix slab-out-of-bounds read in ea_get()
    commit fdf480da5837c23b146c4743c18de97202fcab37 upstream.
    
    During the "size_check" label in ea_get(), the code checks if the extended
    attribute list (xattr) size matches ea_size. If not, it logs
    "ea_get: invalid extended attribute" and calls print_hex_dump().
    
    Here, EALIST_SIZE(ea_buf->xattr) returns 4110417968, which exceeds
    INT_MAX (2,147,483,647). Then ea_size is clamped:
    
    	int size = clamp_t(int, ea_size, 0, EALIST_SIZE(ea_buf->xattr));
    
    Although clamp_t aims to bound ea_size between 0 and 4110417968, the upper
    limit is treated as an int, causing an overflow above 2^31 - 1. This leads
    "size" to wrap around and become negative (-184549328).
    
    The "size" is then passed to print_hex_dump() (called "len" in
    print_hex_dump()), it is passed as type size_t (an unsigned
    type), this is then stored inside a variable called
    "int remaining", which is then assigned to "int linelen" which
    is then passed to hex_dump_to_buffer(). In print_hex_dump()
    the for loop, iterates through 0 to len-1, where len is
    18446744073525002176, calling hex_dump_to_buffer()
    on each iteration:
    
    	for (i = 0; i < len; i += rowsize) {
    		linelen = min(remaining, rowsize);
    		remaining -= rowsize;
    
    		hex_dump_to_buffer(ptr + i, linelen, rowsize, groupsize,
    				   linebuf, sizeof(linebuf), ascii);
    
    		...
    	}
    
    The expected stopping condition (i < len) is effectively broken
    since len is corrupted and very large. This eventually leads to
    the "ptr+i" being passed to hex_dump_to_buffer() to get closer
    to the end of the actual bounds of "ptr", eventually an out of
    bounds access is done in hex_dump_to_buffer() in the following
    for loop:
    
    	for (j = 0; j < len; j++) {
    			if (linebuflen < lx + 2)
    				goto overflow2;
    			ch = ptr[j];
    		...
    	}
    
    To fix this we should validate "EALIST_SIZE(ea_buf->xattr)"
    before it is utilised.

[PATCH_DIFF]
    @@ -559,11 +559,16 @@ static int ea_get(struct inode *inode, struct ea_buffer *ea_buf, int min_size)
     
           size_check:
     	if (EALIST_SIZE(ea_buf->xattr) != ea_size) {
-		int size = clamp_t(int, ea_size, 0, EALIST_SIZE(ea_buf->xattr));
-
-		printk(KERN_ERR "ea_get: invalid extended attribute\n");
-		print_hex_dump(KERN_ERR, "", DUMP_PREFIX_ADDRESS, 16, 1,
-				     ea_buf->xattr, size, 1);
+		if (unlikely(EALIST_SIZE(ea_buf->xattr) > INT_MAX)) {
+			printk(KERN_ERR "ea_get: extended attribute size too large: %u > INT_MAX\n",
+			       EALIST_SIZE(ea_buf->xattr));
+		} else {
+			int size = clamp_t(int, ea_size, 0, EALIST_SIZE(ea_buf->xattr));
+
+			printk(KERN_ERR "ea_get: invalid extended attribute\n");
+			print_hex_dump(KERN_ERR, "", DUMP_PREFIX_ADDRESS, 16, 1,
+				       ea_buf->xattr, size, 1);
+		}
     		ea_release(inode, ea_buf);
     		rc = -EIO;
     		goto clean_up;



[ROOTCAUSE_ANALYSIS]
1. CVE Identifier
CVE-2025-39735

2. Vulnerability Type
Integer overflow and signed/unsigned conversion leading to slab-out-of-bounds read

3. Root Cause Summary
In jfs’s ea_get(), the code used clamp_t(int, ...) with an upper bound of EALIST_SIZE(ea_buf->xattr) without validating that this upper bound fit in int. When EALIST_SIZE exceeded INT_MAX, the conversion to int overflowed, producing a negative “size” that was then passed to print_hex_dump(), where it was interpreted as a huge size_t and drove unbounded iteration. This caused print_hex_dump()/hex_dump_to_buffer() to read beyond the end of the xattr buffer, triggering a slab-out-of-bounds read. The root cause is missing validation of EALIST_SIZE(ea_buf->xattr) relative to INT_MAX before clamping and dumping.

4. Kernel Subsystem Analysis
1) Affected Subsystem:
JFS filesystem extended attribute handling (fs/jfs) in ea_get()

2) Pre-Patch Flaw:
In the size_check path of ea_get(), the code executed:
- “int size = clamp_t(int, ea_size, 0, EALIST_SIZE(ea_buf->xattr));”
- “print_hex_dump(... ea_buf->xattr, size, 1);”
This trusted EALIST_SIZE() as an int-capable upper bound and passed the potentially overflowed “size” to print_hex_dump() without bounds validation.

3) Trigger Condition:
EALIST_SIZE(ea_buf->xattr) returns a value greater than INT_MAX (e.g., 4110417968), and EALIST_SIZE(...) != ea_size, causing entry into the size_check label. The upper bound overflows when cast to int, making “size” negative; when converted to size_t in print_hex_dump(), it becomes a very large value.

4) Impact Mechanism:
print_hex_dump() treats the negative “size” as a huge unsigned len and iterates:
- for (i = 0; i < len; i += rowsize) { ... hex_dump_to_buffer(ptr + i, linelen, ...); }
Eventually ptr + i moves beyond the actual buffer. hex_dump_to_buffer() then reads past bounds in its loop over j < len, resulting in a slab-out-of-bounds read and potential kernel crash.

5. Patch Analysis
1) Fix Approach:
Add a preemptive validation to reject and log cases where EALIST_SIZE(ea_buf->xattr) exceeds INT_MAX before performing clamp_t or calling print_hex_dump(). If the size is too large, skip the dump and bail out with an error, preventing overflow and unsafe reads.

2) Key Code Changes:
- Introduced:
  if (unlikely(EALIST_SIZE(ea_buf->xattr) > INT_MAX)) {
      printk(... "extended attribute size too large: %u > INT_MAX\n", ...);
  } else {
      int size = clamp_t(int, ea_size, 0, EALIST_SIZE(ea_buf->xattr));
      printk(... "invalid extended attribute\n");
      print_hex_dump(... ea_buf->xattr, size, 1);
  }
- This ensures the clamp upper bound is valid for int and prevents passing a corrupted (overflowed) “size” into print_hex_dump(). The rest of the path still releases and returns -EIO.

3) Locking/Concurrency Impact:
None. The change is purely input validation and logging within ea_get(); no locks or ordering were added or modified.

6. Broader Kernel Security Implications
The fix hardens xattr error handling against malformed filesystem data that could otherwise cause kernel memory safety violations during diagnostic dumping. It underscores the need to validate sizes before type-narrowing (e.g., to int) and before using them as iteration bounds in utility functions. Auditing similar clamp_t(int, ...) patterns and debug print paths across the kernel may prevent analogous signed/unsigned and overflow-induced OOB accesses. Preventing slab-out-of-bounds reads reduces risk of kernel crashes and potential information disclosure via unintended memory reads.

[REQUEST]
Produce a detection plan for a CodeQL-based static checker that would detect similar pre-patch flaws.
Requirements for the plan:
- High-level detection goal (1–2 lines).
- A numbered list of detection steps (objective, conceptual AST/semantic signals, FP mitigation).
- Types of program elements to target (functions, call sites, allocation sites, condition checks, lock boundaries, function return-value uses, etc.).
- Dataflow/taint patterns to consider (if applicable), described conceptually.
- Minimal test cases to validate the checker (positive/negative examples).
- Estimated effort/priority (low/medium/high) and likely false-positive sources.
- A short "Limitations & Assumptions" block.

OUTPUT FORMAT (produce exactly this structure; no extra text):
1. Plan Summary
{one-line summary}

2. Detection Steps
1) Step 1: {objective — conceptual signals — FP mitigation}
2) Step 2: {objective — conceptual signals — FP mitigation}
...
(narrow to ≤12 steps)

3. Target Elements
- {list of element types to inspect}

4. Dataflow / Taint Considerations
- {conceptual taint/flow rules to track}

5. Validation & Test Cases
- Positive: {brief}
- Negative: {brief}
- Test harness notes: {brief}

6. Estimated Effort & Priority
{low/medium/high}

7. Likely False-Positive Sources & Mitigations
- {list}

8. Limitations & Assumptions
- {explicit missing info or assumptions}

CONSTRAINTS:
- Do not emit any CodeQL, SQL, pseudocode, or query fragments.
- Keep answers evidence-based and reference which provided field supported each major choice (e.g., “based on [PATCH_DIFF] hunk that adds X”).
- Output must be machine-parseable: keep the exact numbered section headings as above.