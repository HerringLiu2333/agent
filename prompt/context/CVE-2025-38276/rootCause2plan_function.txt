You are a senior static-analysis engineer and CodeQL design expert.
Task: Based only on the supplied materials, produce a human-readable detection plan (natural-language) for a CodeQL checker that would detect the same class of vulnerability described. DO NOT produce any query code or pseudocode — the output must be purely natural language steps and rationale.

Rules:
1. Only use evidence contained in the sections labeled [PATCH_DESCRIPTION], [PATCH_DIFF], [FUNCTION_CONTENT], and [ROOTCAUSE_ANALYSIS]. Do not invent facts.
2. The plan must be a step-by-step detection strategy in natural language (numbered steps). No code, no query snippets, no regex, no domain-specific language.
3. Each step must state: objective, signals to look for (AST/semantic patterns expressed conceptually), why it maps to the root cause, and how to reduce false positives.
4. Include a short test/validation strategy (what sample cases to run and expected outcomes).
5. List limitations and assumptions (what is Not determinable from inputs).
6. Keep the plan concise: overall ≤ 12 numbered steps and each step ≤ 2 concise sentences. Use bullets where helpful.
7. If information required to design an accurate checker is missing, state it explicitly under "Limitations & Assumptions".

[META]
CVE_NAME: CVE-2025-38276

[INFO]
[PATCH_DESCRIPTION]
    fs/dax: Fix "don't skip locked entries when scanning entries"
    Commit 6be3e21d25ca ("fs/dax: don't skip locked entries when scanning
    entries") introduced a new function, wait_entry_unlocked_exclusive(),
    which waits for the current entry to become unlocked without advancing
    the XArray iterator state.
    
    Waiting for the entry to become unlocked requires dropping the XArray
    lock. This requires calling xas_pause() prior to dropping the lock
    which leaves the xas in a suitable state for the next iteration. However
    this has the side-effect of advancing the xas state to the next index.
    Normally this isn't an issue because xas_for_each() contains code to
    detect this state and thus avoid advancing the index a second time on
    the next loop iteration.
    
    However both callers of and wait_entry_unlocked_exclusive() itself
    subsequently use the xas state to reload the entry. As xas_pause()
    updated the state to the next index this will cause the current entry
    which is being waited on to be skipped. This caused the following
    warning to fire intermittently when running xftest generic/068 on an XFS
    filesystem with FS DAX enabled:
    
    [   35.067397] ------------[ cut here ]------------
    [   35.068229] WARNING: CPU: 21 PID: 1640 at mm/truncate.c:89 truncate_folio_batch_exceptionals+0xd8/0x1e0
    [   35.069717] Modules linked in: nd_pmem dax_pmem nd_btt nd_e820 libnvdimm
    [   35.071006] CPU: 21 UID: 0 PID: 1640 Comm: fstest Not tainted 6.15.0-rc7+ #77 PREEMPT(voluntary)
    [   35.072613] Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.16.3-0-ga6ed6b701f0a-prebuilt.qemu.org 04/01/204
    [   35.074845] RIP: 0010:truncate_folio_batch_exceptionals+0xd8/0x1e0
    [   35.075962] Code: a1 00 00 00 f6 47 0d 20 0f 84 97 00 00 00 4c 63 e8 41 39 c4 7f 0b eb 61 49 83 c5 01 45 39 ec 7e 58 42 f68
    [   35.079522] RSP: 0018:ffffb04e426c7850 EFLAGS: 00010202
    [   35.080359] RAX: 0000000000000000 RBX: ffff9d21e3481908 RCX: ffffb04e426c77f4
    [   35.081477] RDX: ffffb04e426c79e8 RSI: ffffb04e426c79e0 RDI: ffff9d21e34816e8
    [   35.082590] RBP: ffffb04e426c79e0 R08: 0000000000000001 R09: 0000000000000003
    [   35.083733] R10: 0000000000000000 R11: 822b53c0f7a49868 R12: 000000000000001f
    [   35.084850] R13: 0000000000000000 R14: ffffb04e426c78e8 R15: fffffffffffffffe
    [   35.085953] FS:  00007f9134c87740(0000) GS:ffff9d22abba0000(0000) knlGS:0000000000000000
    [   35.087346] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   35.088244] CR2: 00007f9134c86000 CR3: 000000040afff000 CR4: 00000000000006f0
    [   35.089354] Call Trace:
    [   35.089749]  <TASK>
    [   35.090168]  truncate_inode_pages_range+0xfc/0x4d0
    [   35.091078]  truncate_pagecache+0x47/0x60
    [   35.091735]  xfs_setattr_size+0xc7/0x3e0
    [   35.092648]  xfs_vn_setattr+0x1ea/0x270
    [   35.093437]  notify_change+0x1f4/0x510
    [   35.094219]  ? do_truncate+0x97/0xe0
    [   35.094879]  do_truncate+0x97/0xe0
    [   35.095640]  path_openat+0xabd/0xca0
    [   35.096278]  do_filp_open+0xd7/0x190
    [   35.096860]  do_sys_openat2+0x8a/0xe0
    [   35.097459]  __x64_sys_openat+0x6d/0xa0
    [   35.098076]  do_syscall_64+0xbb/0x1d0
    [   35.098647]  entry_SYSCALL_64_after_hwframe+0x77/0x7f
    [   35.099444] RIP: 0033:0x7f9134d81fc1
    [   35.100033] Code: 75 57 89 f0 25 00 00 41 00 3d 00 00 41 00 74 49 80 3d 2a 26 0e 00 00 74 6d 89 da 48 89 ee bf 9c ff ff ff5
    [   35.102993] RSP: 002b:00007ffcd41e0d10 EFLAGS: 00000202 ORIG_RAX: 0000000000000101
    [   35.104263] RAX: ffffffffffffffda RBX: 0000000000000242 RCX: 00007f9134d81fc1
    [   35.105452] RDX: 0000000000000242 RSI: 00007ffcd41e1200 RDI: 00000000ffffff9c
    [   35.106663] RBP: 00007ffcd41e1200 R08: 0000000000000000 R09: 0000000000000064
    [   35.107923] R10: 00000000000001a4 R11: 0000000000000202 R12: 0000000000000066
    [   35.109112] R13: 0000000000100000 R14: 0000000000100000 R15: 0000000000000400
    [   35.110357]  </TASK>
    [   35.110769] irq event stamp: 8415587
    [   35.111486] hardirqs last  enabled at (8415599): [<ffffffff8d74b562>] __up_console_sem+0x52/0x60
    [   35.113067] hardirqs last disabled at (8415610): [<ffffffff8d74b547>] __up_console_sem+0x37/0x60
    [   35.114575] softirqs last  enabled at (8415300): [<ffffffff8d6ac625>] handle_softirqs+0x315/0x3f0
    [   35.115933] softirqs last disabled at (8415291): [<ffffffff8d6ac811>] __irq_exit_rcu+0xa1/0xc0
    [   35.117316] ---[ end trace 0000000000000000 ]---
    
    Fix this by using xas_reset() instead, which is equivalent in
    implementation to xas_pause() but does not advance the XArray state.

[PATCH_DIFF]
     @@ -257,7 +257,7 @@ static void *wait_entry_unlocked_exclusive(struct xa_state *xas, void *entry)
     		wq = dax_entry_waitqueue(xas, entry, &ewait.key);
     		prepare_to_wait_exclusive(wq, &ewait.wait,
     					TASK_UNINTERRUPTIBLE);
     -		xas_pause(xas);
     +		xas_reset(xas);
     		xas_unlock_irq(xas);
     		schedule();
     		finish_wait(wq, &ewait.wait);

[FUNCTION_CONTENT]
static void *wait_entry_unlocked_exclusive(struct xa_state *xas, void *entry)
{
	struct wait_exceptional_entry_queue ewait;
	wait_queue_head_t *wq;

	init_wait(&ewait.wait);
	ewait.wait.func = wake_exceptional_entry_func;

	while (unlikely(dax_is_locked(entry))) {
		wq = dax_entry_waitqueue(xas, entry, &ewait.key);
		prepare_to_wait_exclusive(wq, &ewait.wait,
					TASK_UNINTERRUPTIBLE);
		xas_pause(xas);
		xas_unlock_irq(xas);
		schedule();
		finish_wait(wq, &ewait.wait);
		xas_lock_irq(xas);
		entry = xas_load(xas);
	}

	if (xa_is_internal(entry))
		return NULL;

	return entry;
}



[ROOTCAUSE_ANALYSIS]
1. CVE Identifier
CVE-2025-38276

2. Vulnerability Type
Incorrect iterator state handling under lock drop (concurrency/logic bug causing entry skip)

3. Root Cause Summary
wait_entry_unlocked_exclusive() used xas_pause(xas) before dropping the XArray lock, which advances the iterator state to the next index. The function (and its callers) then reload the entry via xas_load(xas) after reacquiring the lock, inadvertently loading the next index instead of the original entry being waited on. This causes the currently locked DAX entry to be skipped during scans, violating scan correctness and leading to exceptional entries not being processed as intended.

4. Kernel Subsystem Analysis
1) Affected Subsystem:
fs/dax (Direct Access) interacting with XArray iteration and truncate paths.

2) Pre-Patch Flaw:
- In wait_entry_unlocked_exclusive(), the sequence:
  - prepare_to_wait_exclusive(...);
  - xas_pause(xas);
  - xas_unlock_irq(xas);
  - schedule();
  - ... entry = xas_load(xas);
  advances xas to the next index due to xas_pause(), so xas_load() no longer refers to the entry just waited on.
- xas_for_each() normally compensates for xas_pause(), but this path performs a direct xas_load() instead of iterating, defeating that safeguard.

3) Trigger Condition:
- Encountering a locked DAX exceptional entry during XArray scanning that requires waiting (e.g., during truncate or pagecache/exceptions removal), leading wait_entry_unlocked_exclusive() to drop the XArray lock and sleep.
- Reproduction observed with xfstests generic/068 on XFS with FS DAX enabled.

4) Impact Mechanism:
- The locked entry being waited on is skipped when scanning resumes, leaving an exceptional DAX entry unprocessed in the XArray.
- This breaks expectations in truncate paths, intermittently triggering warnings in truncate_folio_batch_exceptionals(), and may leave stale entries or inconsistencies until later passes.

5. Patch Analysis
1) Fix Approach:
Replace xas_pause(xas) with xas_reset(xas) before dropping the XArray lock so that the iterator state does not advance, ensuring the subsequent xas_load(xas) reloads the same index that was waited on.

2) Key Code Changes:
- Single-line change in wait_entry_unlocked_exclusive():
  - xas_pause(xas) -> xas_reset(xas)
- As described, xas_reset() is equivalent in preparing state for unlock but does not advance to the next index, preventing the skip.

3) Locking/Concurrency Impact:
- The function still correctly drops the XArray lock to wait on the waitqueue and reacquires it afterward.
- Using xas_reset() preserves the iterator index across the lock drop, aligning with the intended semantics of “wait without advancing,” restoring atomicity of “wait then reload same entry” across the sleep and eliminating the race/skip window introduced by xas_pause().

6. Broader Kernel Security Implications
- Ensures correctness of DAX exceptional entry scanning, preventing skipped entries that can trigger WARNs and violate truncate/invalidation invariants.
- Avoids potential denial of service on systems configured with panic_on_warn=1 and reduces risk of filesystem state inconsistencies caused by incomplete processing of exceptional entries.
- Reinforces correct XArray iterator handling patterns when dropping locks to wait, which is broadly applicable to other XArray-using subsystems.

[REQUEST]
Produce a detection plan for a CodeQL-based static checker that would detect similar pre-patch flaws.
Requirements for the plan:
- High-level detection goal (1–2 lines).
- A numbered list of detection steps (objective, conceptual AST/semantic signals, FP mitigation).
- Types of program elements to target (functions, call sites, allocation sites, condition checks, lock boundaries, function return-value uses, etc.).
- Dataflow/taint patterns to consider (if applicable), described conceptually.
- Minimal test cases to validate the checker (positive/negative examples).
- Estimated effort/priority (low/medium/high) and likely false-positive sources.
- A short "Limitations & Assumptions" block.

OUTPUT FORMAT (produce exactly this structure; no extra text):
1. Plan Summary
{one-line summary}

2. Detection Steps
1) Step 1: {objective — conceptual signals — FP mitigation}
2) Step 2: {objective — conceptual signals — FP mitigation}
...
(narrow to ≤12 steps)

3. Target Elements
- {list of element types to inspect}

4. Dataflow / Taint Considerations
- {conceptual taint/flow rules to track}

5. Validation & Test Cases
- Positive: {brief}
- Negative: {brief}
- Test harness notes: {brief}

6. Estimated Effort & Priority
{low/medium/high}

7. Likely False-Positive Sources & Mitigations
- {list}

8. Limitations & Assumptions
- {explicit missing info or assumptions}

CONSTRAINTS:
- Do not emit any CodeQL, SQL, pseudocode, or query fragments.
- Keep answers evidence-based and reference which provided field supported each major choice (e.g., “based on [PATCH_DIFF] hunk that adds X”).
- Output must be machine-parseable: keep the exact numbered section headings as above.