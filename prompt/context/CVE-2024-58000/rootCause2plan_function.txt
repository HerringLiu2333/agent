You are a senior static-analysis engineer and CodeQL design expert.
Task: Based only on the supplied materials, produce a human-readable detection plan (natural-language) for a CodeQL checker that would detect the same class of vulnerability described. DO NOT produce any query code or pseudocode — the output must be purely natural language steps and rationale.

Rules:
1. Only use evidence contained in the sections labeled [PATCH_DESCRIPTION], [PATCH_DIFF], [FUNCTION_CONTENT], and [ROOTCAUSE_ANALYSIS]. Do not invent facts.
2. The plan must be a step-by-step detection strategy in natural language (numbered steps). No code, no query snippets, no regex, no domain-specific language.
3. Each step must state: objective, signals to look for (AST/semantic patterns expressed conceptually), why it maps to the root cause, and how to reduce false positives.
4. Include a short test/validation strategy (what sample cases to run and expected outcomes).
5. List limitations and assumptions (what is Not determinable from inputs).
6. Keep the plan concise: overall ≤ 12 numbered steps and each step ≤ 2 concise sentences. Use bullets where helpful.
7. If information required to design an accurate checker is missing, state it explicitly under "Limitations & Assumptions".

[META]
CVE_NAME: CVE-2024-58000

[INFO]
[PATCH_DESCRIPTION]
 io_uring: prevent reg-wait speculations
 [ Upstream commit 29b95ac917927ce9f95bf38797e16333ecb489b1 ]
 
 With *ENTER_EXT_ARG_REG instead of passing a user pointer with arguments
 for the waiting loop the user can specify an offset into a pre-mapped
 region of memory, in which case the
 [offset, offset + sizeof(io_uring_reg_wait)) will be intepreted as the
 argument.

 As we address a kernel array using a user given index, it'd be a subject
 to speculation type of exploits. Use array_index_nospec() to prevent
 that. Make sure to pass not the full region size but truncate by the
 maximum offset allowed considering the structure size.

 Fixes: d617b3147d54c ("io_uring: restore back registered wait arguments")
 Fixes: aa00f67adc2c0 ("io_uring: add support for fixed wait regions")

[PATCH_DIFF]
    diff --git a/io_uring/io_uring.c b/io_uring/io_uring.c
    index 4758f1ba902b94..d062c5c69211ba 100644
    --- a/io_uring/io_uring.c
    +++ b/io_uring/io_uring.c
    @@ -3233,6 +3233,7 @@ static struct io_uring_reg_wait *io_get_ext_arg_reg(struct io_ring_ctx *ctx,
     		     end > ctx->cq_wait_size))
     		return ERR_PTR(-EFAULT);
     
    +	offset = array_index_nospec(offset, ctx->cq_wait_size - size);
     	return ctx->cq_wait_arg + offset;

[FUNCTION_CONTENT]
static struct io_uring_reg_wait *io_get_ext_arg_reg(struct io_ring_ctx *ctx,
			const struct io_uring_getevents_arg __user *uarg)
{
	unsigned long size = sizeof(struct io_uring_reg_wait);
	unsigned long offset = (uintptr_t)uarg;
	unsigned long end;

	if (unlikely(offset % sizeof(long)))
		return ERR_PTR(-EFAULT);

	/* also protects from NULL ->cq_wait_arg as the size would be 0 */
	if (unlikely(check_add_overflow(offset, size, &end) ||
		     end > ctx->cq_wait_size))
		return ERR_PTR(-EFAULT);

	return ctx->cq_wait_arg + offset;
}



[ROOTCAUSE_ANALYSIS]
1. CVE Identifier
CVE-2024-58000

2. Vulnerability Type
Speculative execution (Spectre v1) bounds-check bypass leading to kernel information disclosure via side channels

3. Root Cause Summary
io_get_ext_arg_reg() uses a user-controlled offset to index into a kernel-mapped array (ctx->cq_wait_arg) and only performs architectural bounds checks. The code lacks speculation barriers/sanitization, allowing CPUs to speculatively bypass the checks and compute ctx->cq_wait_arg + offset, enabling out-of-bounds speculative reads. Specifically, after verifying alignment and that “end <= ctx->cq_wait_size,” it directly executes “return ctx->cq_wait_arg + offset;” without array_index_nospec(), leaving it vulnerable to Spectre v1.

4. Kernel Subsystem Analysis
1) Affected Subsystem:
io_uring (registered wait arguments and fixed wait regions handling)

2) Pre-Patch Flaw:
In io_get_ext_arg_reg(struct io_ring_ctx *ctx, const struct io_uring_getevents_arg __user *uarg), the user-provided pointer value is treated as a byte offset and, after simple bounds/overflow checks, used as an index into ctx->cq_wait_arg: “return ctx->cq_wait_arg + offset;” This indexing lacks array_index_nospec()-based sanitization, making it susceptible to speculation attacks.

3) Trigger Condition:
A malicious user invokes ENTER_EXT_ARG_REG and supplies a crafted uarg value (offset) while training the branch predictor to mispredict the bounds check (“end > ctx->cq_wait_size”). Under speculative execution, the CPU can compute and access ctx->cq_wait_arg + offset before the check resolves.

4) Impact Mechanism:
Speculative out-of-bounds reads from the kernel’s pre-mapped cq_wait_arg region can leak adjacent kernel memory via microarchitectural side channels (cache/timing), despite architectural checks preventing the access from becoming architecturally visible.

5. Patch Analysis
1) Fix Approach:
Introduce array_index_nospec() to sanitize the user-controlled offset against a strict maximum index, preventing speculative out-of-bounds accesses. The limit passed to array_index_nospec is reduced to “ctx->cq_wait_size - size” to reflect the maximum valid starting offset for a struct io_uring_reg_wait.

2) Key Code Changes:
- Added: “offset = array_index_nospec(offset, ctx->cq_wait_size - size);”
- This is placed after the overflow and bounds checks and before computing the return pointer, ensuring speculative safety while preserving functional behavior.

3) Locking/Concurrency Impact:
No locking or concurrency semantics changed. The patch solely adds speculative execution mitigation and does not alter synchronization, ordering, or RCU/atomic behavior.

6. Broader Kernel Security Implications
Hardening user-influenced indices with array_index_nospec is essential to mitigate Spectre v1-style leaks throughout the kernel, especially in interfaces like io_uring that expose high-performance, user-driven control paths. This change reduces the kernel’s side-channel attack surface by ensuring validated indices cannot be abused speculatively. It aligns io_uring with established kernel-wide speculative execution mitigations and prevents information disclosure without affecting architectural correctness or performance significantly.

[REQUEST]
Produce a detection plan for a CodeQL-based static checker that would detect similar pre-patch flaws.
Requirements for the plan:
- High-level detection goal (1–2 lines).
- A numbered list of detection steps (objective, conceptual AST/semantic signals, FP mitigation).
- Types of program elements to target (functions, call sites, allocation sites, condition checks, lock boundaries, function return-value uses, etc.).
- Dataflow/taint patterns to consider (if applicable), described conceptually.
- Minimal test cases to validate the checker (positive/negative examples).
- Estimated effort/priority (low/medium/high) and likely false-positive sources.
- A short "Limitations & Assumptions" block.

OUTPUT FORMAT (produce exactly this structure; no extra text):
1. Plan Summary
{one-line summary}

2. Detection Steps
1) Step 1: {objective — conceptual signals — FP mitigation}
2) Step 2: {objective — conceptual signals — FP mitigation}
...
(narrow to ≤12 steps)

3. Target Elements
- {list of element types to inspect}

4. Dataflow / Taint Considerations
- {conceptual taint/flow rules to track}

5. Validation & Test Cases
- Positive: {brief}
- Negative: {brief}
- Test harness notes: {brief}

6. Estimated Effort & Priority
{low/medium/high}

7. Likely False-Positive Sources & Mitigations
- {list}

8. Limitations & Assumptions
- {explicit missing info or assumptions}

CONSTRAINTS:
- Do not emit any CodeQL, SQL, pseudocode, or query fragments.
- Keep answers evidence-based and reference which provided field supported each major choice (e.g., “based on [PATCH_DIFF] hunk that adds X”).
- Output must be machine-parseable: keep the exact numbered section headings as above.